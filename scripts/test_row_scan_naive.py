"""
æœ´ç´ ç‰ˆæœ¬è¡Œæ‰«æç®—å­çš„æ­£ç¡®æ€§ä¸æ€§èƒ½æµ‹è¯•ï¼ˆä½¿ç”¨ OpenMP å¹¶è¡Œï¼Œä½†ä¸ä½¿ç”¨ SVE åŠ é€Ÿï¼‰ã€‚

è¿è¡Œæ–¹å¼:
    python -m scripts.test_row_scan_naive
"""

from __future__ import annotations

import argparse
import torch

from kernels.sve_sparse_gemm import row_scan_naive, measure_latency


def reference(act: torch.Tensor, thr: float):
    """å‚è€ƒå®ç°ï¼šä½¿ç”¨ Python å¾ªç¯è®¡ç®—æ¯è¡Œçš„éé›¶å…ƒç´ ç´¢å¼•"""
    M, K = act.shape
    ref_row_nnz = []
    ref_indices = []
    for m in range(M):
        idx = [k for k in range(K) if abs(float(act[m, k])) >= thr]
        ref_row_nnz.append(len(idx))
        ref_indices.append(idx)
    return ref_row_nnz, ref_indices


def baseline_get_sparse_indices(activation: torch.Tensor, threshold: float) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    ä»ç¨€ç– activation ä¸­æå–éé›¶å…ƒç´ çš„ç´¢å¼•ä¿¡æ¯ï¼ˆbaseline å®ç°ï¼Œä½¿ç”¨ PyTorch æ“ä½œï¼‰ã€‚
    
    å‚ç…§ test_sve_sparse_gemm.py ä¸­çš„å®ç°æ–¹å¼ï¼Œä½†ä½¿ç”¨é˜ˆå€¼è€Œéç®€å•çš„éé›¶æ£€æµ‹ã€‚
    
    Returns:
        nz_counts: æˆå¯¹å­˜å‚¨çš„ (row_idx, count)ï¼Œé•¿åº¦ä¸º 2 * num_nz_rows
        nz_col_indices: æ‰å¹³åŒ–çš„åˆ—ç´¢å¼•å‘é‡
        row_offsets: æ¯è¡Œçš„åç§»é‡ï¼Œé•¿åº¦ä¸º M + 1
    """
    M, K = activation.shape
    nz_pairs = []
    nz_col_indices_list = []
    
    for m in range(M):
        row = activation[m]
        # ä½¿ç”¨é˜ˆå€¼æ£€æµ‹ï¼šabs(row) >= threshold
        nz_mask = torch.abs(row) >= threshold
        nz_idx = torch.nonzero(nz_mask, as_tuple=False).flatten()
        if len(nz_idx) > 0:
            nz_pairs.extend([m, len(nz_idx)])
            nz_col_indices_list.append(nz_idx)
    
    nz_counts = torch.tensor(nz_pairs, dtype=torch.int64) if len(nz_pairs) > 0 else torch.tensor([], dtype=torch.int64)
    nz_col_indices = torch.cat(nz_col_indices_list, dim=0).to(dtype=torch.int64) if len(nz_col_indices_list) > 0 else torch.tensor([], dtype=torch.int64)
    
    # è®¡ç®— row_offsets
    row_offsets = torch.zeros(M + 1, dtype=torch.int64)
    offset = 0
    for m in range(M):
        row_offsets[m] = offset
        row = activation[m]
        nz_mask = torch.abs(row) >= threshold
        nz_count = torch.sum(nz_mask).item()
        offset += nz_count
    row_offsets[M] = offset
    
    return nz_counts, nz_col_indices, row_offsets


def get_sparse_indices_pytorch_style(activation: torch.Tensor, threshold: float) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    ä»ç¨€ç– activation ä¸­æå–éé›¶å…ƒç´ çš„ç´¢å¼•ä¿¡æ¯ï¼ˆPyTorch é£æ ¼å®ç°ï¼Œå‚ç…§ test_sve_sparse_gemm.pyï¼‰ã€‚
    
    ä½¿ç”¨ abs(row) >= threshold è¿›è¡Œé˜ˆå€¼æ£€æµ‹ï¼Œè¿”å›ä¸‰ä¸ªå€¼ï¼šnz_counts, nz_col_indices, row_offsetsã€‚
    
    Returns:
        nz_counts: æˆå¯¹å­˜å‚¨çš„ (row_idx, count)ï¼Œé•¿åº¦ä¸º 2 * num_nz_rows
        nz_col_indices: æ‰å¹³åŒ–çš„åˆ—ç´¢å¼•å‘é‡ï¼ˆuint32ï¼‰
        row_offsets: æ¯è¡Œçš„åç§»é‡ï¼Œé•¿åº¦ä¸º M + 1
    """
    M, K = activation.shape
    row_offsets = [0]
    nz_col_indices = []
    nz_pairs = []
    
    for m in range(M):
        row = activation[m]
        # ä½¿ç”¨é˜ˆå€¼æ£€æµ‹ï¼šabs(row) >= threshold
        nz_mask = torch.abs(row) >= threshold
        nz_idx = torch.nonzero(nz_mask, as_tuple=False).flatten()
        nz_col_indices.append(nz_idx.to(dtype=torch.uint32))
        nnz = len(nz_idx)
        row_offsets.append(row_offsets[-1] + nnz)
        if nnz > 0:
            nz_pairs.extend([m, nnz])
    
    row_offsets_t = torch.tensor(row_offsets, dtype=torch.int64)
    nz_col_indices_t = torch.cat(nz_col_indices, dim=0) if len(nz_col_indices) > 0 else torch.tensor([], dtype=torch.uint32)
    nz_counts_t = torch.tensor(nz_pairs, dtype=torch.int64) if len(nz_pairs) > 0 else torch.tensor([], dtype=torch.int64)
    
    return nz_counts_t, nz_col_indices_t, row_offsets_t


def check_correctness(M: int, K: int, threshold: float, seed: int) -> None:
    """æµ‹è¯•ç®—å­çš„æ­£ç¡®æ€§"""
    print("=" * 60)
    print("æµ‹è¯•1: æ­£ç¡®æ€§éªŒè¯")
    print("=" * 60)

    torch.manual_seed(seed)
    act = torch.rand(M, K, dtype=torch.float32, device="cpu").contiguous()

    # Naive å®ç°
    nz_counts_naive, nz_col_indices_naive, row_offsets_naive = row_scan_naive(act, threshold, verbose=False)

    # Baseline å®ç°ï¼ˆPyTorchï¼‰
    nz_counts_baseline, nz_col_indices_baseline, row_offsets_baseline = baseline_get_sparse_indices(act, threshold)

    # ---- correctness checks ----
    ref_row_nnz, ref_indices = reference(act, threshold)

    # row_offsets prefix sum check
    assert row_offsets_naive.numel() == M + 1, f"row_offsets é•¿åº¦åº”ä¸º {M + 1}ï¼Œå®é™…ä¸º {row_offsets_naive.numel()}"
    assert int(row_offsets_naive[0].item()) == 0, "row_offsets[0] åº”ä¸º 0"
    assert int(row_offsets_naive[M].item()) == nz_col_indices_naive.numel(), \
        f"row_offsets[M] åº”ä¸º {nz_col_indices_naive.numel()}ï¼Œå®é™…ä¸º {int(row_offsets_naive[M].item())}"

    # per-row slice check (ä¸ reference æ¯”è¾ƒ)
    for m in range(M):
        s = int(row_offsets_naive[m].item())
        e = int(row_offsets_naive[m + 1].item())
        got = nz_col_indices_naive[s:e].tolist()
        exp = ref_indices[m]
        if got != exp:
            raise AssertionError(
                f"Row {m} mismatch: got {got[:16]}... len={len(got)} vs exp {exp[:16]}... len={len(exp)}"
            )

    # nz_counts format check (only nnz>0, increasing rows)
    assert nz_counts_naive.numel() % 2 == 0, "nz_counts é•¿åº¦åº”ä¸ºå¶æ•°"
    pairs_naive = nz_counts_naive.view(-1, 2).tolist()
    last_row = -1
    for row, nnz in pairs_naive:
        assert nnz > 0, f"è¡Œ {row} çš„éé›¶å…ƒç´ æ•°åº”ä¸ºæ­£æ•°"
        assert row > last_row, f"è¡Œç´¢å¼•åº”é€’å¢ï¼Œä½† {row} <= {last_row}"
        assert nnz == ref_row_nnz[row], f"è¡Œ {row} çš„éé›¶å…ƒç´ æ•°ä¸åŒ¹é…ï¼šæœŸæœ› {ref_row_nnz[row]}ï¼Œå®é™… {nnz}"
        last_row = row

    # ä¸ baseline æ¯”è¾ƒï¼ˆç»Ÿä¸€ç±»å‹ï¼šNaive è¿”å› uint32ï¼Œbaseline è¿”å› int64ï¼‰
    nz_col_indices_naive_int64 = nz_col_indices_naive.to(dtype=torch.int64)
    assert torch.equal(nz_counts_naive, nz_counts_baseline), \
        f"Naive ä¸ baseline çš„ nz_counts ä¸åŒ¹é…"
    assert torch.equal(nz_col_indices_naive_int64, nz_col_indices_baseline), \
        f"Naive ä¸ baseline çš„ nz_col_indices ä¸åŒ¹é…"
    assert torch.equal(row_offsets_naive, row_offsets_baseline), \
        f"Naive ä¸ baseline çš„ row_offsets ä¸åŒ¹é…"

    print(f"âœ… æ­£ç¡®æ€§æµ‹è¯•é€šè¿‡")
    print(f"   æ€»éé›¶å…ƒç´ æ•°: {nz_col_indices_naive.numel()}/{M*K} ({100*nz_col_indices_naive.numel()/(M*K):.1f}%)")
    print(f"   éé›¶è¡Œæ•°: {len(pairs_naive)}/{M} ({100*len(pairs_naive)/M:.1f}%)")
    print(f"   é˜ˆå€¼(threshold): {threshold:.3f}")
    print(f"   âœ… Naive ç»“æœä¸ baseline (PyTorch) ç»“æœä¸€è‡´")


def test_edge_cases() -> None:
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: è¾¹ç•Œæƒ…å†µ")
    print("=" * 60)

    threshold = 0.25

    # æµ‹è¯•1: å…¨é›¶çŸ©é˜µ
    print("æµ‹è¯•2.1: å…¨é›¶çŸ©é˜µ")
    M, K = 10, 20
    act = torch.zeros(M, K, dtype=torch.float32)
    nz_counts, nz_col_indices, row_offsets = row_scan_naive(act, threshold, verbose=False)
    assert nz_counts.numel() == 0, "å…¨é›¶çŸ©é˜µçš„ nz_counts åº”ä¸ºç©º"
    assert nz_col_indices.numel() == 0, "å…¨é›¶çŸ©é˜µçš„ nz_col_indices åº”ä¸ºç©º"
    assert torch.all(row_offsets == 0), "å…¨é›¶çŸ©é˜µçš„ row_offsets åº”å…¨ä¸º 0"
    print("  âœ… é€šè¿‡")

    # æµ‹è¯•2: å…¨éé›¶çŸ©é˜µï¼ˆæ‰€æœ‰å…ƒç´ éƒ½å¤§äºé˜ˆå€¼ï¼‰
    print("æµ‹è¯•2.2: å…¨éé›¶çŸ©é˜µ")
    M, K = 5, 10
    act = torch.ones(M, K, dtype=torch.float32) * (threshold + 0.1)
    nz_counts, nz_col_indices, row_offsets = row_scan_naive(act, threshold, verbose=False)
    assert nz_col_indices.numel() == M * K, f"å…¨éé›¶çŸ©é˜µçš„éé›¶å…ƒç´ æ•°åº”ä¸º {M*K}"
    assert row_offsets[-1].item() == M * K, f"row_offsets[-1] åº”ä¸º {M*K}"
    print("  âœ… é€šè¿‡")

    # æµ‹è¯•3: å•è¡Œå•å…ƒç´ 
    print("æµ‹è¯•2.3: å•è¡Œå•å…ƒç´ ")
    M, K = 1, 1
    act = torch.tensor([[threshold + 0.1]], dtype=torch.float32)
    nz_counts, nz_col_indices, row_offsets = row_scan_naive(act, threshold, verbose=False)
    assert nz_col_indices.numel() == 1, "å•è¡Œå•å…ƒç´ çŸ©é˜µçš„éé›¶å…ƒç´ æ•°åº”ä¸º 1"
    assert nz_col_indices[0].item() == 0, "åˆ—ç´¢å¼•åº”ä¸º 0"
    print("  âœ… é€šè¿‡")

    # æµ‹è¯•4: ä¸åŒè¡Œå…·æœ‰ä¸åŒçš„éé›¶å…ƒç´ æ•°
    print("æµ‹è¯•2.4: ä¸åŒè¡Œå…·æœ‰ä¸åŒçš„éé›¶å…ƒç´ æ•°")
    M, K = 5, 10
    act = torch.zeros(M, K, dtype=torch.float32)
    act[0, :1] = threshold + 0.1  # 1 ä¸ªéé›¶
    act[1, :3] = threshold + 0.1  # 3 ä¸ªéé›¶
    act[2, :] = threshold + 0.1   # 10 ä¸ªéé›¶
    act[3, :0] = threshold + 0.1  # 0 ä¸ªéé›¶ï¼ˆå…¨é›¶è¡Œï¼‰
    act[4, :5] = threshold + 0.1  # 5 ä¸ªéé›¶
    nz_counts, nz_col_indices, row_offsets = row_scan_naive(act, threshold, verbose=False)
    ref_row_nnz, ref_indices = reference(act, threshold)
    pairs = nz_counts.view(-1, 2).tolist()
    for row, nnz in pairs:
        assert nnz == ref_row_nnz[row], f"è¡Œ {row} çš„éé›¶å…ƒç´ æ•°ä¸åŒ¹é…"
    print("  âœ… é€šè¿‡")


def benchmark_performance(M: int, K: int, threshold: float, seed: int) -> None:
    """æ€§èƒ½æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: æ€§èƒ½æµ‹è¯•")
    print("=" * 60)

    torch.manual_seed(seed)
    act = torch.rand(M, K, dtype=torch.float32, device="cpu").contiguous()

    # æµ‹è¯• Naive ç®—å­æ€§èƒ½
    def naive_fn():
        return row_scan_naive(act, threshold, verbose=False)

    lat_naive = measure_latency(naive_fn, warmup=10, iters=1000000)
    print(f"â±ï¸  Naive row_scan ç®—å­å¹³å‡å»¶è¿Ÿ: {lat_naive:.4f} ms")
    print(f"   è¾“å…¥å½¢çŠ¶: activation={act.shape}")
    print(f"   é˜ˆå€¼(threshold): {threshold:.3f}")

    # # è·å–å®é™…éé›¶å…ƒç´ æ•°ç”¨äºæ˜¾ç¤º
    # _, nz_col_indices, _ = row_scan_naive(act, threshold, verbose=False)
    # print(f"   æ€»éé›¶å…ƒç´ æ•°: {nz_col_indices.numel()}/{M*K} ({100*nz_col_indices.numel()/(M*K):.1f}%)")

    # # æµ‹è¯• Baseline (PyTorch) å®ç°æ€§èƒ½
    # def baseline_fn():
    #     return baseline_get_sparse_indices(act, threshold)

    # lat_baseline = measure_latency(baseline_fn, warmup=10, iters=50)
    # print(f"\nâ±ï¸  Baseline (PyTorch) å®ç°å¹³å‡å»¶è¿Ÿ: {lat_baseline:.4f} ms")
    
    # # è®¡ç®—åŠ é€Ÿæ¯”
    # if lat_baseline > 0:
    #     speedup = lat_baseline / lat_naive
    #     print(f"   åŠ é€Ÿæ¯”: {speedup:.2f}x")
    #     if speedup > 1.0:
    #         print(f"   âœ… Naive å®ç°æ¯” Baseline å¿« {speedup:.2f}x")
    #     else:
    #         print(f"   âš ï¸  Naive å®ç°æ¯” Baseline æ…¢ {1.0/speedup:.2f}x")
    # else:
    #     print(f"   âš ï¸  æ— æ³•è®¡ç®—åŠ é€Ÿæ¯”ï¼ˆbaseline å»¶è¿Ÿä¸º 0ï¼‰")


def benchmark_indices_generation_comparison(M: int, K: int, threshold: float, seed: int) -> None:
    """
    å¯¹æ¯”ä¸åŒæ–¹æ³•ç”Ÿæˆ nz_counts_t, nz_col_indices_t, row_offsets_t çš„æ€§èƒ½ã€‚
    
    å¯¹æ¯”çš„æ–¹æ³•ï¼š
    1. row_scan_naive - æœ´ç´ å¹¶è¡Œå®ç°ï¼ˆOpenMPï¼Œæ—  SVEï¼‰
    2. baseline_get_sparse_indices - Baseline PyTorch å®ç°
    3. get_sparse_indices_pytorch_style - PyTorch é£æ ¼å®ç°ï¼ˆå‚ç…§ test_sve_sparse_gemm.pyï¼‰
    """
    print("\n" + "=" * 60)
    print("æµ‹è¯•4: ç´¢å¼•ç”Ÿæˆæ–¹æ³•æ€§èƒ½å¯¹æ¯”")
    print("=" * 60)

    torch.manual_seed(seed)
    act = torch.rand(M, K, dtype=torch.float32, device="cpu").contiguous()

    # è·å–å®é™…éé›¶å…ƒç´ æ•°ç”¨äºæ˜¾ç¤º
    _, nz_col_indices_ref, _ = row_scan_naive(act, threshold, verbose=False)
    nnz = nz_col_indices_ref.numel()
    print(f"è¾“å…¥å½¢çŠ¶: activation={act.shape}")
    print(f"é˜ˆå€¼(threshold): {threshold:.3f}")
    print(f"æ€»éé›¶å…ƒç´ æ•°: {nnz}/{M*K} ({100*nnz/(M*K):.1f}%)")
    print()

    # æ–¹æ³•1: Naive å®ç°
    def naive_fn():
        return row_scan_naive(act, threshold, verbose=False)

    lat_naive = measure_latency(naive_fn, warmup=10, iters=10000000)
    print(f"â±ï¸  æ–¹æ³•1 - Naive row_scan å®ç°ï¼ˆOpenMP å¹¶è¡Œï¼Œæ—  SVEï¼‰:")
    print(f"   å¹³å‡å»¶è¿Ÿ: {lat_naive:.4f} ms")

    # æ–¹æ³•2: Baseline PyTorch å®ç°
    def baseline_fn():
        return baseline_get_sparse_indices(act, threshold)

    lat_baseline = measure_latency(baseline_fn, warmup=10, iters=50)
    print(f"\nâ±ï¸  æ–¹æ³•2 - Baseline PyTorch å®ç°:")
    print(f"   å¹³å‡å»¶è¿Ÿ: {lat_baseline:.4f} ms")
    if lat_naive > 0:
        speedup_vs_baseline = lat_baseline / lat_naive
        print(f"   ç›¸å¯¹ Naive çš„åŠ é€Ÿæ¯”: {speedup_vs_baseline:.2f}x" + 
              (f" (Naive å¿« {speedup_vs_baseline:.2f}x)" if speedup_vs_baseline > 1.0 
               else f" (Naive æ…¢ {1.0/speedup_vs_baseline:.2f}x)"))

    # æ–¹æ³•3: PyTorch é£æ ¼å®ç°ï¼ˆå‚ç…§ test_sve_sparse_gemm.pyï¼‰
    def pytorch_style_fn():
        return get_sparse_indices_pytorch_style(act, threshold)

    lat_pytorch_style = measure_latency(pytorch_style_fn, warmup=10, iters=50)
    print(f"\nâ±ï¸  æ–¹æ³•3 - PyTorch é£æ ¼å®ç°ï¼ˆå‚ç…§ test_sve_sparse_gemm.pyï¼‰:")
    print(f"   å¹³å‡å»¶è¿Ÿ: {lat_pytorch_style:.4f} ms")
    if lat_naive > 0:
        speedup_vs_pytorch_style = lat_pytorch_style / lat_naive
        print(f"   ç›¸å¯¹ Naive çš„åŠ é€Ÿæ¯”: {speedup_vs_pytorch_style:.2f}x" + 
              (f" (Naive å¿« {speedup_vs_pytorch_style:.2f}x)" if speedup_vs_pytorch_style > 1.0 
               else f" (Naive æ…¢ {1.0/speedup_vs_pytorch_style:.2f}x)"))

    # æ­£ç¡®æ€§éªŒè¯ï¼šç¡®ä¿ä¸‰ç§æ–¹æ³•äº§ç”Ÿç›¸åŒçš„ç»“æœ
    print(f"\nğŸ“‹ æ­£ç¡®æ€§éªŒè¯:")
    nz_counts_naive, nz_col_indices_naive, row_offsets_naive = row_scan_naive(act, threshold, verbose=False)
    nz_counts_baseline, nz_col_indices_baseline, row_offsets_baseline = baseline_get_sparse_indices(act, threshold)
    nz_counts_pytorch, nz_col_indices_pytorch, row_offsets_pytorch = get_sparse_indices_pytorch_style(act, threshold)

    # æ¯”è¾ƒç»“æœï¼ˆæ³¨æ„ nz_col_indices çš„ç±»å‹å¯èƒ½ä¸åŒï¼šNaive è¿”å› uint32ï¼Œbaseline è¿”å› int64ï¼‰
    nz_col_indices_naive_int64 = nz_col_indices_naive.to(dtype=torch.int64)
    nz_col_indices_pytorch_int64 = nz_col_indices_pytorch.to(dtype=torch.int64)

    match_naive_baseline = (
        torch.equal(nz_counts_naive, nz_counts_baseline) and
        torch.equal(nz_col_indices_naive_int64, nz_col_indices_baseline) and
        torch.equal(row_offsets_naive, row_offsets_baseline)
    )
    match_naive_pytorch = (
        torch.equal(nz_counts_naive, nz_counts_pytorch) and
        torch.equal(nz_col_indices_naive_int64, nz_col_indices_pytorch_int64) and
        torch.equal(row_offsets_naive, row_offsets_pytorch)
    )

    if match_naive_baseline:
        print(f"   âœ… Naive ä¸ Baseline ç»“æœä¸€è‡´")
    else:
        print(f"   âŒ Naive ä¸ Baseline ç»“æœä¸ä¸€è‡´")

    if match_naive_pytorch:
        print(f"   âœ… Naive ä¸ PyTorch é£æ ¼å®ç°ç»“æœä¸€è‡´")
    else:
        print(f"   âŒ Naive ä¸ PyTorch é£æ ¼å®ç°ç»“æœä¸ä¸€è‡´")

    # æ€§èƒ½æ€»ç»“
    print(f"\nğŸ“Š æ€§èƒ½æ€»ç»“:")
    latencies = [
        ("Naive row_scan (OpenMP)", lat_naive),
        ("Baseline PyTorch", lat_baseline),
        ("PyTorch é£æ ¼", lat_pytorch_style),
    ]
    latencies.sort(key=lambda x: x[1])
    fastest = latencies[0]
    print(f"   æœ€å¿«æ–¹æ³•: {fastest[0]} ({fastest[1]:.4f} ms)")
    for name, lat in latencies[1:]:
        if fastest[1] > 0:
            speedup = lat / fastest[1]
            print(f"   {name}: {lat:.4f} ms (æ…¢ {speedup:.2f}x)")


def main() -> None:
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    parser = argparse.ArgumentParser()
    parser.add_argument("--M", type=int, default=256, help="activation è¡Œæ•°")
    parser.add_argument("--K", type=int, default=4096, help="activation åˆ—æ•°")
    parser.add_argument("--threshold", type=float, default=0.8, help="é˜ˆå€¼")
    parser.add_argument("--seed", type=int, default=0, help="éšæœºç§å­")
    args = parser.parse_args()

    try:
        check_correctness(M=args.M, K=args.K, threshold=args.threshold, seed=args.seed)
        test_edge_cases()
        benchmark_performance(M=args.M, K=args.K, threshold=args.threshold, seed=args.seed + 1)
        # benchmark_indices_generation_comparison(M=args.M, K=args.K, threshold=args.threshold, seed=args.seed + 2)
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        print("=" * 60)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
