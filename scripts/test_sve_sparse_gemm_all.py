"""
ARM SVE ç¨€ç– GEMM ç®—å­çš„ç»¼åˆæµ‹è¯•è„šæœ¬ã€‚

æœ¬è„šæœ¬æµ‹è¯•ä¸åŒç¨€ç–æ ¼å¼çš„ç¨€ç–åŒ–ç®—å­å’ŒGEMMç®—å­çš„ç»„åˆï¼ˆå…±17ä¸ªï¼‰ï¼š

è‡ªå®šä¹‰ SVE ç®—å­ï¼ˆ13ä¸ªï¼‰ï¼š
- iCSR æ ¼å¼ç»„åˆï¼šthr_sparsify_to_icsr(_sve) + sparse_gemm_icsr(_sve_gather)
- CSR æ ¼å¼ç»„åˆï¼šthr_sparsify_to_csr(_sve) + sparse_gemm_csr(_sve_gather)
- COO æ ¼å¼ç»„åˆï¼šthr_sparsify_to_coo(_sve) + sparse_gemm_coo(_sve_gather)
- CSC æ ¼å¼ç»„åˆï¼šthr_sparsify_to_csc + sparse_gemm_csc

PyTorch å‚è€ƒå®ç°ï¼ˆ4ä¸ªï¼‰ï¼š
- ç¨ å¯† matmul
- ç¨€ç– CSR + sparse.mm
- ç¨€ç– CSC + sparse.mm
- é€‰æ‹©æ€§åŠ è½½ weight éé›¶è¡Œ + matmul

æµ‹è¯•å†…å®¹ï¼š
1. æ­£ç¡®æ€§éªŒè¯ï¼šä¸PyTorchå‚è€ƒå®ç°æ¯”è¾ƒ
2. æ€§èƒ½æµ‹è¯•ï¼šæµ‹é‡æ¯ä¸ªç»„åˆçš„å»¶è¿Ÿ
3. åŠ é€Ÿæ¯”è®¡ç®—ï¼šè®¡ç®—ç›¸å¯¹äºPyTorchç¨ å¯†å®ç°çš„åŠ é€Ÿæ¯”
4. æ€§èƒ½æ’åï¼šæ‰¾å‡ºæœ€å¿«çš„ç®—å­ç»„åˆ

è¿è¡Œæ–¹å¼:
    python -m scripts.test_sparse_formats
    python -m scripts.test_sparse_formats --threshold 0.8 --M 16 --K 512 --N 1024
"""

from __future__ import annotations

import argparse
import torch
import time
from typing import Any, Dict, List, Tuple

from kernels.cpp_sve_sparse_gemm import (
    # iCSR ç®—å­
    SparseGEMMiCSRSVEGatherKernel,
    SparseGEMMICSRKernel,
    thr_sparsify_to_icsr,
    thr_sparsify_to_icsr_sve,
    # CSR ç®—å­
    SparseGEMMCSRKernel,
    SparseGEMMCSRSVEGatherKernel,
    thr_sparsify_to_csr,
    thr_sparsify_to_csr_sve,
    # COO ç®—å­
    SparseGEMMCOOKernel,
    SparseGEMMCOOSVEGatherKernel,
    thr_sparsify_to_coo,
    thr_sparsify_to_coo_sve,
    # CSC ç®—å­
    SparseGEMMCSCKernel,
    thr_sparsify_to_csc,
    # å·¥å…·å‡½æ•°
    load_sve_sparse_gemm_extension,
)
from kernels.kernel_utils import measure_latency

try:
    import psutil  # type: ignore
except Exception:
    psutil = None  # type: ignore


def _make_random_sparse_activation(
    M: int,
    K: int,
    seed: int,
) -> torch.Tensor:
    """ç”Ÿæˆéšæœº activation çŸ©é˜µï¼ˆfloat32ï¼‰ã€‚"""
    g = torch.Generator()
    g.manual_seed(seed)
    x = torch.rand(M, K, dtype=torch.float32, generator=g)
    return x


def _apply_threshold(activation: torch.Tensor, threshold: float = 0.0) -> torch.Tensor:
    """å¯¹ activation çŸ©é˜µåº”ç”¨é˜ˆå€¼ï¼šabs(x) >= threshold çš„å€¼ä¿ç•™ï¼Œå…¶ä½™ç½®é›¶ã€‚

    æ³¨æ„ï¼šcpp_sve_sparse_gemm ä¸‹çš„ thr_sparsify_to_* ç³»åˆ—ç®—å­ä½¿ç”¨çš„æ˜¯ abs(x) >= thr çš„åˆ¤å®šï¼›
    è¿™é‡Œå¿…é¡»ä¿æŒä¸€è‡´ï¼Œå¦åˆ™ä¼šå‡ºç°ç³»ç»Ÿæ€§æ­£ç¡®æ€§åå·®ï¼ˆå°¤å…¶æ˜¯ activation å«è´Ÿå€¼æ—¶ï¼‰ã€‚
    """
    return torch.where(activation.abs() >= threshold, activation, torch.zeros_like(activation))


def _print_ranked_latencies(
    title: str,
    latencies: List[Tuple[str, float]],
    baseline_latency: float | None = None,
) -> None:
    """æŒ‰å»¶è¿Ÿä»å¿«åˆ°æ…¢æ‰“å°æ’åï¼Œå¯é€‰æ‰“å°ç›¸å¯¹ baseline çš„åŠ é€Ÿæ¯”ã€‚"""
    print("\n" + "=" * 80)
    print(title)
    print("=" * 80)

    if not latencies:
        print("ï¼ˆæ— æ•°æ®ï¼‰")
        return

    latencies = sorted(latencies, key=lambda x: x[1])
    if baseline_latency is not None and baseline_latency > 0:
        print(f"{'æ’å':<4} {'é¡¹ç›®':<64} {'å»¶è¿Ÿ(ms)':<12} {'åŠ é€Ÿæ¯”':<10}")
        print("-" * 94)
        for rank, (name, latency) in enumerate(latencies, 1):
            speedup = baseline_latency / latency if latency > 0 else 0.0
            print(f"{rank:2d}. {name:64s} {latency:8.4f} ms  {speedup:6.2f}x")
    else:
        print(f"{'æ’å':<4} {'é¡¹ç›®':<72} {'å»¶è¿Ÿ(ms)':<12}")
        print("-" * 92)
        for rank, (name, latency) in enumerate(latencies, 1):
            print(f"{rank:2d}. {name:72s} {latency:8.4f} ms")

    fastest_name, fastest_latency = latencies[0]
    print("\n" + "-" * 80)
    print(f"âš¡ æœ€å¿«: {fastest_name}")
    print(f"   å»¶è¿Ÿ: {fastest_latency:.4f} ms")
    if baseline_latency is not None and baseline_latency > 0 and fastest_latency > 0:
        print(f"   ç›¸æ¯” baseline åŠ é€Ÿæ¯”: {baseline_latency/fastest_latency:.2f}x")


def _maybe_print_cpu_util(prefix: str, interval_s: float = 0.20) -> None:
    """æ‰“å° CPU åˆ©ç”¨ç‡ï¼ˆç³»ç»Ÿ + å½“å‰è¿›ç¨‹ï¼‰ï¼Œbest-effortã€‚

    ä¾èµ– psutilï¼›è‹¥ä¸å¯ç”¨åˆ™é™é»˜è·³è¿‡ï¼ˆmain é‡Œä¼šæ‰“å°ä¸€æ¬¡æç¤ºï¼‰ã€‚
    """
    if psutil is None:
        return

    try:
        proc = psutil.Process()
        # å…ˆè®¾ç½® system åŸºçº¿ï¼Œå†ç”¨ proc çš„é˜»å¡é‡‡æ ·å¾—åˆ°åŒä¸€æ—¶é—´çª—çš„ system åˆ©ç”¨ç‡
        psutil.cpu_percent(interval=None)
        proc_cpu = proc.cpu_percent(interval=interval_s)
        sys_cpu = psutil.cpu_percent(interval=None)

        cpu_cnt = psutil.cpu_count(logical=True) or 1
        proc_cpu_norm = proc_cpu / cpu_cnt

        mem = proc.memory_info().rss / (1024 * 1024)
        threads = proc.num_threads()

        ts = time.strftime("%H:%M:%S")
        print(
            f"[CPU {ts}] {prefix} | sys={sys_cpu:5.1f}% | proc={proc_cpu:6.1f}% "
            f"(norm={proc_cpu_norm:5.1f}%) | rss={mem:7.1f} MB | thr={threads}"
        )
    except Exception:
        # ä¸è®©ç›‘æ§å½±å“æµ‹è¯•æµç¨‹
        return


def _parse_selected_tests(raw_tests: List[str] | None) -> List[str]:
    """è§£æ --tests å‚æ•°ï¼Œæ”¯æŒç©ºæ ¼/é€—å·åˆ†éš”ä¸å¸¸è§åˆ«åã€‚

    å…è®¸é¡¹ï¼š
    - all
    - icsr / csr / coo / csc
    - pytorch
    - gemm-only
    - preprocess-only
    """
    if not raw_tests:
        raw_tests = ["all"]

    tokens: List[str] = []
    for item in raw_tests:
        for part in item.split(","):
            part = part.strip()
            if part:
                tokens.append(part)

    normalized: List[str] = []
    for t in tokens:
        tl = t.strip().lower().replace("_", "-")
        if tl in {"all"}:
            normalized.append("all")
            continue
        if tl in {"icsr", "i-csr", "i_csr"}:
            normalized.append("icsr")
            continue
        if tl in {"csr"}:
            normalized.append("csr")
            continue
        if tl in {"coo"}:
            normalized.append("coo")
            continue
        if tl in {"csc"}:
            normalized.append("csc")
            continue
        if tl in {"pytorch", "torch"}:
            normalized.append("pytorch")
            continue
        if tl in {"gemm-only", "gemmonly", "gemm", "core-gemm", "core-gemm-only"}:
            normalized.append("gemm-only")
            continue
        if tl in {"preprocess-only", "preprocessonly", "preprocess", "pre"}:
            normalized.append("preprocess-only")
            continue

        allowed = "all/icsr/csr/coo/csc/pytorch/gemm-only/preprocess-only"
        raise ValueError(f"--tests åŒ…å«æœªçŸ¥é¡¹: {t!r}ï¼Œå…è®¸é¡¹: {allowed}")

    if "all" in normalized:
        return ["icsr", "csr", "coo", "csc", "pytorch", "gemm-only", "preprocess-only"]

    # å»é‡å¹¶ä¿æŒç”¨æˆ·è¾“å…¥é¡ºåº
    seen = set()
    ordered_unique: List[str] = []
    for t in normalized:
        if t not in seen:
            seen.add(t)
            ordered_unique.append(t)
    return ordered_unique


def verify_correctness_flat(
    results: Dict[str, Tuple[torch.Tensor, float]],
    reference: torch.Tensor,
) -> None:
    """éªŒè¯ä¸€ç»„ï¼ˆæ‰å¹³ï¼‰ç»“æœçš„æ­£ç¡®æ€§ï¼ˆé€é¡¹ä¸ reference å¯¹æ¯”ï¼‰ã€‚"""
    print("\n" + "=" * 80)
    print("æ­£ç¡®æ€§éªŒè¯ï¼ˆæ‰å¹³ç»“æœé›†ï¼‰")
    print("=" * 80)

    all_passed = True
    for name, (result, _) in results.items():
        max_diff = torch.max(torch.abs(result - reference)).item()
        mean_diff = torch.mean(torch.abs(result - reference)).item()
        is_correct = torch.allclose(result, reference, rtol=1e-4, atol=1e-5)
        status = "âœ…" if is_correct else "âŒ"
        print(f"  {status} {name}")
        print(f"      æœ€å¤§è¯¯å·®: {max_diff:.6e}, å¹³å‡è¯¯å·®: {mean_diff:.6e}")
        if not is_correct:
            all_passed = False

    if all_passed:
        print("\nâœ… æ­£ç¡®æ€§æµ‹è¯•é€šè¿‡")
    else:
        print("\nâŒ éƒ¨åˆ†ç»“æœä¸æ­£ç¡®")


def test_core_gemm_only(
    activation: torch.Tensor,
    activation_thresholded: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """åªæµ‹è¯•â€œæ ¸å¿ƒä¹˜æ³•ï¼ˆGEMM å†…æ ¸ï¼‰â€çš„è€—æ—¶ï¼šç¨€ç–è¡¨ç¤ºå…ˆç¼“å­˜ï¼Œè®¡æ—¶å¾ªç¯é‡Œä¸åŒ…å«ç¨€ç–åŒ–ã€‚"""
    print("\n" + "=" * 80)
    print("æ ¸å¿ƒä¹˜æ³•ï¼ˆGEMM-onlyï¼‰å¯¹æ¯”")
    print("=" * 80)

    results: Dict[str, Tuple[torch.Tensor, float]] = {}

    # Baseline: PyTorch dense matmulï¼ˆä¸åŒ…å« threshold çš„ä»£ä»·ï¼Œthresholded ç”±å¤–éƒ¨é¢„å…ˆè®¡ç®—ï¼‰
    print("\n[GEMM-only][PyTorch] torch.matmul(activation_thresholded, weight)")
    def torch_dense_core():
        return torch.matmul(activation_thresholded, weight)

    lat_torch = measure_latency(torch_dense_core, warmup=5, iters=100000)
    results["GEMM-only: PyTorch torch.matmul(thresholded, weight)"] = (torch_dense_core(), lat_torch)
    print(f"  å»¶è¿Ÿ: {lat_torch:.4f} ms")

    # iCSR: å…ˆ sparsify ä¸€æ¬¡ï¼Œè®¡æ—¶å¾ªç¯åªè·‘ sparse_gemm
    print("\n[GEMM-only][iCSR] é¢„å…ˆ thr_sparsify_to_icsr")
    nz_counts, nz_col_indices, row_offsets = thr_sparsify_to_icsr(activation, threshold)

    icsr_sve_gather_kernel = SparseGEMMiCSRSVEGatherKernel.initialize(
        name="sparse_gemm_icsr_sve_gather", target="CPU"
    )
    icsr_sve_gather_op = icsr_sve_gather_kernel.operator(compiled=True)

    icsr_kernel = SparseGEMMICSRKernel.initialize(
        name="sparse_gemm_icsr", target="CPU"
    )
    icsr_op = icsr_kernel.operator(compiled=True)

    print("  - sparse_gemm_icsr_sve_gather")
    def icsr_gemm_gather_only():
        return icsr_sve_gather_op(activation, weight, row_offsets, nz_col_indices)

    lat = measure_latency(icsr_gemm_gather_only, warmup=5, iters=100000)
    results["GEMM-only: iCSR sparse_gemm_icsr_sve_gather (cached indices)"] = (icsr_gemm_gather_only(), lat)
    print(f"    å»¶è¿Ÿ: {lat:.4f} ms")

    print("  - sparse_gemm_icsr")
    def icsr_gemm_only():
        return icsr_op(activation, weight, row_offsets, nz_col_indices)

    lat = measure_latency(icsr_gemm_only, warmup=5, iters=100000)
    results["GEMM-only: iCSR sparse_gemm_icsr (cached indices)"] = (icsr_gemm_only(), lat)
    print(f"    å»¶è¿Ÿ: {lat:.4f} ms")

    # CSR
    print("\n[GEMM-only][CSR] é¢„å…ˆ thr_sparsify_to_csr")
    csr_row_offsets, csr_nz_col_indices, csr_values = thr_sparsify_to_csr(activation, threshold)

    csr_kernel = SparseGEMMCSRKernel.initialize(name="sparse_gemm_csr", target="CPU")
    csr_op = csr_kernel.operator(compiled=True)

    csr_sve_gather_kernel = SparseGEMMCSRSVEGatherKernel.initialize(
        name="sparse_gemm_csr_sve_gather", target="CPU"
    )
    csr_sve_gather_op = csr_sve_gather_kernel.operator(compiled=True)

    print("  - sparse_gemm_csr")
    def csr_gemm_only():
        return csr_op(weight, csr_row_offsets, csr_nz_col_indices, csr_values)

    lat = measure_latency(csr_gemm_only, warmup=5, iters=100000)
    results["GEMM-only: CSR sparse_gemm_csr (cached values)"] = (csr_gemm_only(), lat)
    print(f"    å»¶è¿Ÿ: {lat:.4f} ms")

    print("  - sparse_gemm_csr_sve_gather")
    def csr_gemm_gather_only():
        return csr_sve_gather_op(weight, csr_row_offsets, csr_nz_col_indices, csr_values)

    lat = measure_latency(csr_gemm_gather_only, warmup=5, iters=100000)
    results["GEMM-only: CSR sparse_gemm_csr_sve_gather (cached values)"] = (csr_gemm_gather_only(), lat)
    print(f"    å»¶è¿Ÿ: {lat:.4f} ms")

    # COO
    print("\n[GEMM-only][COO] é¢„å…ˆ thr_sparsify_to_coo")
    coo_row_indices, coo_col_indices, coo_values = thr_sparsify_to_coo(activation, threshold)
    M = int(activation.size(0))

    coo_kernel = SparseGEMMCOOKernel.initialize(name="sparse_gemm_coo", target="CPU")
    coo_op = coo_kernel.operator(compiled=True)

    coo_sve_gather_kernel = SparseGEMMCOOSVEGatherKernel.initialize(
        name="sparse_gemm_coo_sve_gather", target="CPU"
    )
    coo_sve_gather_op = coo_sve_gather_kernel.operator(compiled=True)

    # sparse_gemm_coo éœ€è¦ uint32 col_indicesï¼Œthr_sparsify_to_coo å·²è¿”å› uint32
    print("  - sparse_gemm_coo")
    def coo_gemm_only():
        return coo_op(weight, coo_row_indices, coo_col_indices, coo_values, M)

    lat = measure_latency(coo_gemm_only, warmup=5, iters=100000)
    results["GEMM-only: COO sparse_gemm_coo (cached triplets)"] = (coo_gemm_only(), lat)
    print(f"    å»¶è¿Ÿ: {lat:.4f} ms")

    print("  - sparse_gemm_coo_sve_gather")
    def coo_gemm_gather_only():
        return coo_sve_gather_op(weight, coo_row_indices, coo_col_indices, coo_values, M)

    lat = measure_latency(coo_gemm_gather_only, warmup=5, iters=100000)
    results["GEMM-only: COO sparse_gemm_coo_sve_gather (cached triplets)"] = (coo_gemm_gather_only(), lat)
    print(f"    å»¶è¿Ÿ: {lat:.4f} ms")

    # CSC
    print("\n[GEMM-only][CSC] é¢„å…ˆ thr_sparsify_to_csc")
    csc_col_ptr, csc_row_indices, csc_values = thr_sparsify_to_csc(activation, threshold)

    csc_kernel = SparseGEMMCSCKernel.initialize(name="sparse_gemm_csc", target="CPU")
    csc_op = csc_kernel.operator(compiled=True)

    print("  - sparse_gemm_csc")
    def csc_gemm_only():
        return csc_op(weight, csc_col_ptr, csc_row_indices, csc_values, M, 0)

    lat = measure_latency(csc_gemm_only, warmup=5, iters=100000)
    results["GEMM-only: CSC sparse_gemm_csc (cached CSC)"] = (csc_gemm_only(), lat)
    print(f"    å»¶è¿Ÿ: {lat:.4f} ms")

    return results


def test_preprocess_only(
    activation: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[Any, float]]:
    """åªæµ‹è¯•è¾“å…¥ç¨€ç–çŸ©é˜µå¤„ç†ï¼ˆç¨€ç–åŒ–/æ ¼å¼è½¬æ¢ï¼‰è€—æ—¶ï¼šä¸åŒ…å«ä»»ä½• GEMMã€‚"""
    print("\n" + "=" * 80)
    print("è¾“å…¥ç¨€ç–çŸ©é˜µå¤„ç†ï¼ˆPreprocess-onlyï¼‰å¯¹æ¯”")
    print("=" * 80)

    results: Dict[str, Tuple[Any, float]] = {}

    # Baseline 1: ä»… thresholdï¼ˆå¯¹é½ cpp åˆ¤å®š abs(x) >= thrï¼‰
    print("\n[Preprocess-only][PyTorch] _apply_threshold")
    def torch_threshold_only():
        return _apply_threshold(activation, threshold=threshold)

    lat = measure_latency(torch_threshold_only, warmup=5, iters=10)
    results["Preprocess-only: PyTorch _apply_threshold(abs>=thr)"] = (torch_threshold_only(), lat)
    print(f"  å»¶è¿Ÿ: {lat:.4f} ms")

    # Baseline 2: threshold + to_sparse_csrï¼ˆç«¯åˆ°ç«¯çš„ PyTorch CSR æ„å»ºï¼‰
    print("\n[Preprocess-only][PyTorch] threshold + to_sparse_csr")
    def torch_to_sparse_csr():
        x = _apply_threshold(activation, threshold=threshold)
        sp = x.to_sparse_csr()
        # è®¿é—® componentsï¼Œé¿å… lazy è·¯å¾„æŠŠå·¥ä½œå»¶ååˆ°åç»­é˜¶æ®µ
        _ = sp.crow_indices()
        _ = sp.col_indices()
        _ = sp.values()
        return sp

    lat = measure_latency(torch_to_sparse_csr, warmup=5, iters=10)
    results["Preprocess-only: PyTorch threshold + to_sparse_csr()"] = (torch_to_sparse_csr(), lat)
    print(f"  å»¶è¿Ÿ: {lat:.4f} ms")

    # Baseline 3: threshold + to_sparse_cscï¼ˆç«¯åˆ°ç«¯çš„ PyTorch CSC æ„å»ºï¼‰
    print("\n[Preprocess-only][PyTorch] threshold + to_sparse_csc")
    def torch_to_sparse_csc():
        x = _apply_threshold(activation, threshold=threshold)
        sp = x.to_sparse_csc()
        _ = sp.ccol_indices()
        _ = sp.row_indices()
        _ = sp.values()
        return sp

    lat = measure_latency(torch_to_sparse_csc, warmup=5, iters=10)
    results["Preprocess-only: PyTorch threshold + to_sparse_csc()"] = (torch_to_sparse_csc(), lat)
    print(f"  å»¶è¿Ÿ: {lat:.4f} ms")

    # Custom: iCSR sparsify
    print("\n[Preprocess-only][iCSR] thr_sparsify_to_icsr / thr_sparsify_to_icsr_sve")
    def icsr_pre_1():
        return thr_sparsify_to_icsr(activation, threshold)

    lat = measure_latency(icsr_pre_1, warmup=5, iters=100000)
    results["Preprocess-only: iCSR thr_sparsify_to_icsr"] = (icsr_pre_1(), lat)
    print(f"  - thr_sparsify_to_icsr: {lat:.4f} ms")

    def icsr_pre_2():
        return thr_sparsify_to_icsr_sve(activation, threshold)

    lat = measure_latency(icsr_pre_2, warmup=5, iters=100000)
    results["Preprocess-only: iCSR thr_sparsify_to_icsr_sve"] = (icsr_pre_2(), lat)
    print(f"  - thr_sparsify_to_icsr_sve: {lat:.4f} ms")

    # Custom: CSR sparsify
    print("\n[Preprocess-only][CSR] thr_sparsify_to_csr / thr_sparsify_to_csr_sve")
    def csr_pre_1():
        return thr_sparsify_to_csr(activation, threshold)

    lat = measure_latency(csr_pre_1, warmup=5, iters=100000)
    results["Preprocess-only: CSR thr_sparsify_to_csr"] = (csr_pre_1(), lat)
    print(f"  - thr_sparsify_to_csr: {lat:.4f} ms")

    def csr_pre_2():
        return thr_sparsify_to_csr_sve(activation, threshold)

    lat = measure_latency(csr_pre_2, warmup=5, iters=100000)
    results["Preprocess-only: CSR thr_sparsify_to_csr_sve"] = (csr_pre_2(), lat)
    print(f"  - thr_sparsify_to_csr_sve: {lat:.4f} ms")

    # Custom: COO sparsify
    print("\n[Preprocess-only][COO] thr_sparsify_to_coo / thr_sparsify_to_coo_sve")
    def coo_pre_1():
        return thr_sparsify_to_coo(activation, threshold)

    lat = measure_latency(coo_pre_1, warmup=5, iters=100000)
    results["Preprocess-only: COO thr_sparsify_to_coo"] = (coo_pre_1(), lat)
    print(f"  - thr_sparsify_to_coo: {lat:.4f} ms")

    def coo_pre_2():
        return thr_sparsify_to_coo_sve(activation, threshold)

    lat = measure_latency(coo_pre_2, warmup=5, iters=100000)
    results["Preprocess-only: COO thr_sparsify_to_coo_sve"] = (coo_pre_2(), lat)
    print(f"  - thr_sparsify_to_coo_sve: {lat:.4f} ms")

    # Custom: CSC sparsify
    print("\n[Preprocess-only][CSC] thr_sparsify_to_csc")
    def csc_pre():
        return thr_sparsify_to_csc(activation, threshold)

    lat = measure_latency(csc_pre, warmup=5, iters=100000)
    results["Preprocess-only: CSC thr_sparsify_to_csc"] = (csc_pre(), lat)
    print(f"  - thr_sparsify_to_csc: {lat:.4f} ms")

    return results


# =============================================================================
# iCSR æ ¼å¼ç»„åˆæµ‹è¯•
# =============================================================================

def test_icsr_combinations(
    activation: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """
    æµ‹è¯• iCSR æ ¼å¼çš„ç¨€ç–åŒ–å’ŒGEMMç®—å­çš„æ‰€æœ‰ç»„åˆã€‚
    
    ç»„åˆï¼š
    - thr_sparsify_to_icsr + sparse_gemm_icsr_sve_gather
    - thr_sparsify_to_icsr_sve + sparse_gemm_icsr_sve_gather
    - thr_sparsify_to_icsr + sparse_gemm_icsr
    - thr_sparsify_to_icsr_sve + sparse_gemm_icsr
    
    Returns:
        Dict[ç»„åˆåç§°, (ç»“æœ, å»¶è¿Ÿ)]
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯• iCSR æ ¼å¼ç»„åˆ")
    print("=" * 80)
    
    results = {}
    
    # åˆå§‹åŒ– GEMM ç®—å­
    icsr_sve_gather_kernel = SparseGEMMiCSRSVEGatherKernel.initialize(
        name="sparse_gemm_icsr_sve_gather", target="CPU"
    )
    icsr_sve_gather_op = icsr_sve_gather_kernel.operator(compiled=True)
    
    icsr_kernel = SparseGEMMICSRKernel.initialize(
        name="sparse_gemm_icsr", target="CPU"
    )
    icsr_op = icsr_kernel.operator(compiled=True)
    
    # ç»„åˆ 1: thr_sparsify_to_icsr + sparse_gemm_icsr_sve_gather
    print("\n[iCSR-1] thr_sparsify_to_icsr + sparse_gemm_icsr_sve_gather")
    def icsr_combo1():
        nz_counts, nz_col_indices, row_offsets = thr_sparsify_to_icsr(activation, threshold)
        return icsr_sve_gather_op(activation, weight, row_offsets, nz_col_indices)
    
    lat1 = measure_latency(icsr_combo1, warmup=5, iters=100000)
    result1 = icsr_combo1()
    results["iCSR-1: thr_sparsify_to_icsr + sparse_gemm_icsr_sve_gather"] = (result1, lat1)
    print(f"  å»¶è¿Ÿ: {lat1:.4f} ms")
    
    # ç»„åˆ 2: thr_sparsify_to_icsr_sve + sparse_gemm_icsr_sve_gather
    print("\n[iCSR-2] thr_sparsify_to_icsr_sve + sparse_gemm_icsr_sve_gather")
    def icsr_combo2():
        nz_counts, nz_col_indices, row_offsets = thr_sparsify_to_icsr_sve(activation, threshold)
        return icsr_sve_gather_op(activation, weight, row_offsets, nz_col_indices)
    
    lat2 = measure_latency(icsr_combo2, warmup=5, iters=100000)
    result2 = icsr_combo2()
    results["iCSR-2: thr_sparsify_to_icsr_sve + sparse_gemm_icsr_sve_gather"] = (result2, lat2)
    print(f"  å»¶è¿Ÿ: {lat2:.4f} ms")
    
    # ç»„åˆ 3: thr_sparsify_to_icsr + sparse_gemm_icsr
    print("\n[iCSR-3] thr_sparsify_to_icsr + sparse_gemm_icsr")
    def icsr_combo3():
        nz_counts, nz_col_indices, row_offsets = thr_sparsify_to_icsr(activation, threshold)
        return icsr_op(activation, weight, row_offsets, nz_col_indices)
    
    lat3 = measure_latency(icsr_combo3, warmup=5, iters=100000)
    result3 = icsr_combo3()
    results["iCSR-3: thr_sparsify_to_icsr + sparse_gemm_icsr"] = (result3, lat3)
    print(f"  å»¶è¿Ÿ: {lat3:.4f} ms")
    
    # ç»„åˆ 4: thr_sparsify_to_icsr_sve + sparse_gemm_icsr
    print("\n[iCSR-4] thr_sparsify_to_icsr_sve + sparse_gemm_icsr")
    def icsr_combo4():
        nz_counts, nz_col_indices, row_offsets = thr_sparsify_to_icsr_sve(activation, threshold)
        return icsr_op(activation, weight, row_offsets, nz_col_indices)
    
    lat4 = measure_latency(icsr_combo4, warmup=5, iters=100000)
    result4 = icsr_combo4()
    results["iCSR-4: thr_sparsify_to_icsr_sve + sparse_gemm_icsr"] = (result4, lat4)
    print(f"  å»¶è¿Ÿ: {lat4:.4f} ms")
    
    return results


# =============================================================================
# CSR æ ¼å¼ç»„åˆæµ‹è¯•
# =============================================================================

def test_csr_combinations(
    activation: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """
    æµ‹è¯• CSR æ ¼å¼çš„ç¨€ç–åŒ–å’ŒGEMMç®—å­çš„æ‰€æœ‰ç»„åˆã€‚
    
    ç»„åˆï¼š
    - thr_sparsify_to_csr + sparse_gemm_csr
    - thr_sparsify_to_csr_sve + sparse_gemm_csr
    - thr_sparsify_to_csr + sparse_gemm_csr_sve_gather
    - thr_sparsify_to_csr_sve + sparse_gemm_csr_sve_gather
    
    Returns:
        Dict[ç»„åˆåç§°, (ç»“æœ, å»¶è¿Ÿ)]
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯• CSR æ ¼å¼ç»„åˆ")
    print("=" * 80)
    
    results = {}
    
    # åˆå§‹åŒ– GEMM ç®—å­
    csr_kernel = SparseGEMMCSRKernel.initialize(
        name="sparse_gemm_csr", target="CPU"
    )
    csr_op = csr_kernel.operator(compiled=True)
    
    csr_sve_gather_kernel = SparseGEMMCSRSVEGatherKernel.initialize(
        name="sparse_gemm_csr_sve_gather", target="CPU"
    )
    csr_sve_gather_op = csr_sve_gather_kernel.operator(compiled=True)
    
    # ç»„åˆ 1: thr_sparsify_to_csr + sparse_gemm_csr
    print("\n[CSR-1] thr_sparsify_to_csr + sparse_gemm_csr")
    def csr_combo1():
        row_offsets, nz_col_indices, values = thr_sparsify_to_csr(activation, threshold)
        return csr_op(weight, row_offsets, nz_col_indices, values)
    
    lat1 = measure_latency(csr_combo1, warmup=5, iters=100000)
    result1 = csr_combo1()
    results["CSR-1: thr_sparsify_to_csr + sparse_gemm_csr"] = (result1, lat1)
    print(f"  å»¶è¿Ÿ: {lat1:.4f} ms")
    
    # ç»„åˆ 2: thr_sparsify_to_csr_sve + sparse_gemm_csr
    print("\n[CSR-2] thr_sparsify_to_csr_sve + sparse_gemm_csr")
    def csr_combo2():
        row_offsets, nz_col_indices, values = thr_sparsify_to_csr_sve(activation, threshold)
        return csr_op(weight, row_offsets, nz_col_indices, values)
    
    lat2 = measure_latency(csr_combo2, warmup=5, iters=100000)
    result2 = csr_combo2()
    results["CSR-2: thr_sparsify_to_csr_sve + sparse_gemm_csr"] = (result2, lat2)
    print(f"  å»¶è¿Ÿ: {lat2:.4f} ms")
    
    # ç»„åˆ 3: thr_sparsify_to_csr + sparse_gemm_csr_sve_gather
    print("\n[CSR-3] thr_sparsify_to_csr + sparse_gemm_csr_sve_gather")
    def csr_combo3():
        row_offsets, nz_col_indices, values = thr_sparsify_to_csr(activation, threshold)
        return csr_sve_gather_op(weight, row_offsets, nz_col_indices, values)
    
    lat3 = measure_latency(csr_combo3, warmup=5, iters=100000)
    result3 = csr_combo3()
    results["CSR-3: thr_sparsify_to_csr + sparse_gemm_csr_sve_gather"] = (result3, lat3)
    print(f"  å»¶è¿Ÿ: {lat3:.4f} ms")
    
    # ç»„åˆ 4: thr_sparsify_to_csr_sve + sparse_gemm_csr_sve_gather
    print("\n[CSR-4] thr_sparsify_to_csr_sve + sparse_gemm_csr_sve_gather")
    def csr_combo4():
        row_offsets, nz_col_indices, values = thr_sparsify_to_csr_sve(activation, threshold)
        return csr_sve_gather_op(weight, row_offsets, nz_col_indices, values)
    
    lat4 = measure_latency(csr_combo4, warmup=5, iters=100000)
    result4 = csr_combo4()
    results["CSR-4: thr_sparsify_to_csr_sve + sparse_gemm_csr_sve_gather"] = (result4, lat4)
    print(f"  å»¶è¿Ÿ: {lat4:.4f} ms")
    
    return results


# =============================================================================
# COO æ ¼å¼ç»„åˆæµ‹è¯•
# =============================================================================

def test_coo_combinations(
    activation: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """
    æµ‹è¯• COO æ ¼å¼çš„ç¨€ç–åŒ–å’ŒGEMMç®—å­çš„æ‰€æœ‰ç»„åˆã€‚
    
    ç»„åˆï¼š
    - thr_sparsify_to_coo + sparse_gemm_coo
    - thr_sparsify_to_coo_sve + sparse_gemm_coo
    - thr_sparsify_to_coo + sparse_gemm_coo_sve_gather
    - thr_sparsify_to_coo_sve + sparse_gemm_coo_sve_gather
    
    Returns:
        Dict[ç»„åˆåç§°, (ç»“æœ, å»¶è¿Ÿ)]
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯• COO æ ¼å¼ç»„åˆ")
    print("=" * 80)
    
    results = {}
    
    # åˆå§‹åŒ– GEMM ç®—å­
    coo_kernel = SparseGEMMCOOKernel.initialize(
        name="sparse_gemm_coo", target="CPU"
    )
    coo_op = coo_kernel.operator(compiled=True)
    
    coo_sve_gather_kernel = SparseGEMMCOOSVEGatherKernel.initialize(
        name="sparse_gemm_coo_sve_gather", target="CPU"
    )
    coo_sve_gather_op = coo_sve_gather_kernel.operator(compiled=True)
    
    # C++ ç®—å­ç­¾åéœ€è¦æ˜¾å¼ä¼ å…¥ Mï¼ˆç¨€ç–çŸ©é˜µè¡Œæ•°ï¼‰
    M = int(activation.size(0))

    # ç»„åˆ 1: thr_sparsify_to_coo + sparse_gemm_coo
    print("\n[COO-1] thr_sparsify_to_coo + sparse_gemm_coo")
    def coo_combo1():
        row_indices, col_indices, values = thr_sparsify_to_coo(activation, threshold)
        # sparse_gemm_coo éœ€è¦ uint32 çš„ col_indicesï¼Œthr_sparsify_to_coo å·²è¿”å› uint32
        return coo_op(weight, row_indices, col_indices, values, M)
    
    lat1 = measure_latency(coo_combo1, warmup=5, iters=100000)
    result1 = coo_combo1()
    results["COO-1: thr_sparsify_to_coo + sparse_gemm_coo"] = (result1, lat1)
    print(f"  å»¶è¿Ÿ: {lat1:.4f} ms")
    
    # ç»„åˆ 2: thr_sparsify_to_coo_sve + sparse_gemm_coo
    print("\n[COO-2] thr_sparsify_to_coo_sve + sparse_gemm_coo")
    def coo_combo2():
        row_indices, col_indices, values = thr_sparsify_to_coo_sve(activation, threshold)
        # sparse_gemm_coo éœ€è¦ uint32 çš„ col_indicesï¼Œthr_sparsify_to_coo_sve å·²è¿”å› uint32
        return coo_op(weight, row_indices, col_indices, values, M)
    
    lat2 = measure_latency(coo_combo2, warmup=5, iters=100000)
    result2 = coo_combo2()
    results["COO-2: thr_sparsify_to_coo_sve + sparse_gemm_coo"] = (result2, lat2)
    print(f"  å»¶è¿Ÿ: {lat2:.4f} ms")
    
    # ç»„åˆ 3: thr_sparsify_to_coo + sparse_gemm_coo_sve_gather
    print("\n[COO-3] thr_sparsify_to_coo + sparse_gemm_coo_sve_gather")
    def coo_combo3():
        row_indices, col_indices, values = thr_sparsify_to_coo(activation, threshold)
        # sparse_gemm_coo_sve_gather éœ€è¦ uint32 çš„ col_indicesï¼Œå·²ç»æ˜¯ uint32
        return coo_sve_gather_op(weight, row_indices, col_indices, values, M)
    
    lat3 = measure_latency(coo_combo3, warmup=5, iters=100000)
    result3 = coo_combo3()
    results["COO-3: thr_sparsify_to_coo + sparse_gemm_coo_sve_gather"] = (result3, lat3)
    print(f"  å»¶è¿Ÿ: {lat3:.4f} ms")
    
    # ç»„åˆ 4: thr_sparsify_to_coo_sve + sparse_gemm_coo_sve_gather
    print("\n[COO-4] thr_sparsify_to_coo_sve + sparse_gemm_coo_sve_gather")
    def coo_combo4():
        row_indices, col_indices, values = thr_sparsify_to_coo_sve(activation, threshold)
        # sparse_gemm_coo_sve_gather éœ€è¦ uint32 çš„ col_indicesï¼Œå·²ç»æ˜¯ uint32
        return coo_sve_gather_op(weight, row_indices, col_indices, values, M)
    
    lat4 = measure_latency(coo_combo4, warmup=5, iters=100000)
    result4 = coo_combo4()
    results["COO-4: thr_sparsify_to_coo_sve + sparse_gemm_coo_sve_gather"] = (result4, lat4)
    print(f"  å»¶è¿Ÿ: {lat4:.4f} ms")
    
    return results


# =============================================================================
# CSC æ ¼å¼ç»„åˆæµ‹è¯•
# =============================================================================

def test_csc_combinations(
    activation: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """
    æµ‹è¯• CSC æ ¼å¼çš„ç¨€ç–åŒ–å’ŒGEMMç®—å­çš„æ‰€æœ‰ç»„åˆã€‚
    
    ç»„åˆï¼š
    - thr_sparsify_to_csc + sparse_gemm_csc
    
    Returns:
        Dict[ç»„åˆåç§°, (ç»“æœ, å»¶è¿Ÿ)]
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯• CSC æ ¼å¼ç»„åˆ")
    print("=" * 80)
    
    results = {}
    
    # åˆå§‹åŒ– GEMM ç®—å­
    csc_kernel = SparseGEMMCSCKernel.initialize(
        name="sparse_gemm_csc", target="CPU"
    )
    csc_op = csc_kernel.operator(compiled=True)
    
    M = activation.size(0)
    
    # ç»„åˆ 1: thr_sparsify_to_csc + sparse_gemm_csc
    print("\n[CSC-1] thr_sparsify_to_csc + sparse_gemm_csc")
    def csc_combo1():
        col_ptr, row_indices, values = thr_sparsify_to_csc(activation, threshold)
        return csc_op(weight, col_ptr, row_indices, values, M, 0)
    
    lat1 = measure_latency(csc_combo1, warmup=5, iters=100000)
    result1 = csc_combo1()
    results["CSC-1: thr_sparsify_to_csc + sparse_gemm_csc"] = (result1, lat1)
    print(f"  å»¶è¿Ÿ: {lat1:.4f} ms")
    
    return results


# =============================================================================
# PyTorch å‚è€ƒå®ç°æµ‹è¯•
# =============================================================================

def test_pytorch_references(
    activation: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """
    æµ‹è¯•PyTorchçš„å‚è€ƒå®ç°ã€‚
    
    æµ‹è¯•æ–¹æ³•ï¼š
    - PyTorch ç¨ å¯† matmul
    - PyTorch ç¨€ç– CSR + sparse.mm
    - PyTorch ç¨€ç– CSC + sparse.mm
    - PyTorch é€‰æ‹©æ€§åŠ è½½ weight éé›¶è¡Œ + matmul
    
    Returns:
        Dict[ç»„åˆåç§°, (ç»“æœ, å»¶è¿Ÿ)]
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯• PyTorch å‚è€ƒå®ç°")
    print("=" * 80)
    
    results = {}
    
    # å¯ç”¨ MKL-DNN
    torch.backends.mkldnn.enabled = True
    
    # PyTorch ç¨ å¯† matmul
    print("\n[PyTorch-1] ç¨ å¯† matmul")
    def pytorch_dense_fn():
        activation_thresholded = _apply_threshold(activation, threshold=threshold)
        return torch.matmul(activation_thresholded, weight)
    
    lat1 = measure_latency(pytorch_dense_fn, warmup=5, iters=100000)
    result1 = pytorch_dense_fn()
    results["PyTorch-1: ç¨ å¯† matmul"] = (result1, lat1)
    print(f"  å»¶è¿Ÿ: {lat1:.4f} ms")
    
    # PyTorch ç¨€ç– CSR + sparse.mm
    print("\n[PyTorch-2] ç¨€ç– CSR + sparse.mm")
    def pytorch_sparse_csr_fn():
        activation_thresholded = _apply_threshold(activation, threshold=threshold)
        sp_act = activation_thresholded.to_sparse_csr()
        return torch.sparse.mm(sp_act, weight)
    
    lat2 = measure_latency(pytorch_sparse_csr_fn, warmup=5, iters=100000)
    result2 = pytorch_sparse_csr_fn()
    results["PyTorch-2: ç¨€ç– CSR + sparse.mm"] = (result2, lat2)
    print(f"  å»¶è¿Ÿ: {lat2:.4f} ms")
    
    # PyTorch ç¨€ç– CSC + sparse.mm
    print("\n[PyTorch-3] ç¨€ç– CSC + sparse.mm")
    def pytorch_sparse_csc_fn():
        activation_thresholded = _apply_threshold(activation, threshold=threshold)
        sp_act = activation_thresholded.to_sparse_csc()
        return torch.sparse.mm(sp_act, weight)
    
    lat3 = measure_latency(pytorch_sparse_csc_fn, warmup=5, iters=100000)
    result3 = pytorch_sparse_csc_fn()
    results["PyTorch-3: ç¨€ç– CSC + sparse.mm"] = (result3, lat3)
    print(f"  å»¶è¿Ÿ: {lat3:.4f} ms")
    
    # PyTorch é€‰æ‹©æ€§åŠ è½½ weight éé›¶è¡Œ + matmul
    print("\n[PyTorch-4] é€‰æ‹©æ€§åŠ è½½ weight éé›¶è¡Œ + matmul")
    def pytorch_selective_weight_fn():
        activation_thresholded = _apply_threshold(activation, threshold=threshold)
        M, K = activation_thresholded.shape
        N = weight.shape[1]
        
        # åˆå§‹åŒ–è¾“å‡º
        output = torch.zeros(M, N, dtype=torch.float32)
        
        # å¯¹æ¯ä¸€è¡Œè¿›è¡Œå¤„ç†
        for m in range(M):
            # æ‰¾å‡ºè¯¥è¡Œçš„éé›¶åˆ—ç´¢å¼•
            nz_cols = torch.nonzero(activation_thresholded[m], as_tuple=False).flatten()
            
            if nz_cols.numel() > 0:
                # åªé€‰æ‹© weight ä¸­å¯¹åº”çš„éé›¶è¡Œ
                act_nz = activation_thresholded[m, nz_cols]  # (nnz,)
                weight_nz = weight[nz_cols, :]  # (nnz, N)
                
                # è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼š(1, nnz) @ (nnz, N) -> (1, N)
                output[m] = torch.matmul(act_nz.unsqueeze(0), weight_nz).squeeze(0)
        
        return output
    
    lat4 = measure_latency(pytorch_selective_weight_fn, warmup=5, iters=100000)
    result4 = pytorch_selective_weight_fn()
    results["PyTorch-4: é€‰æ‹©æ€§åŠ è½½ weight éé›¶è¡Œ + matmul"] = (result4, lat4)
    print(f"  å»¶è¿Ÿ: {lat4:.4f} ms")
    
    return results


# =============================================================================
# æ­£ç¡®æ€§éªŒè¯å’Œç»¼åˆæ¯”è¾ƒ
# =============================================================================

def verify_correctness(
    all_results: Dict[str, Dict[str, Tuple[torch.Tensor, float]]],
    reference: torch.Tensor,
) -> None:
    """éªŒè¯æ‰€æœ‰ç®—å­ç»„åˆçš„æ­£ç¡®æ€§ã€‚"""
    print("\n" + "=" * 80)
    print("æ­£ç¡®æ€§éªŒè¯")
    print("=" * 80)
    
    all_passed = True
    
    for format_name, results in all_results.items():
        print(f"\n{format_name}:")
        for combo_name, (result, latency) in results.items():
            max_diff = torch.max(torch.abs(result - reference)).item()
            mean_diff = torch.mean(torch.abs(result - reference)).item()
            
            is_correct = torch.allclose(result, reference, rtol=1e-4, atol=1e-5)
            status = "âœ…" if is_correct else "âŒ"
            
            print(f"  {status} {combo_name}")
            print(f"      æœ€å¤§è¯¯å·®: {max_diff:.6e}, å¹³å‡è¯¯å·®: {mean_diff:.6e}")
            
            if not is_correct:
                all_passed = False
    
    if all_passed:
        print("\nâœ… æ‰€æœ‰ç»„åˆçš„æ­£ç¡®æ€§æµ‹è¯•é€šè¿‡")
    else:
        print("\nâŒ éƒ¨åˆ†ç»„åˆçš„æ­£ç¡®æ€§æµ‹è¯•å¤±è´¥")


def print_performance_summary(
    all_results: Dict[str, Dict[str, Tuple[torch.Tensor, float]]],
) -> None:
    """æ‰“å°æ€§èƒ½å¯¹æ¯”æ€»ç»“ã€‚"""
    print("\n" + "=" * 80)
    print("æ€§èƒ½å¯¹æ¯”æ€»ç»“")
    print("=" * 80)
    
    # æ”¶é›†æ‰€æœ‰å»¶è¿Ÿæ•°æ®
    all_latencies = []
    pytorch_dense_latency = None
    
    for format_name, results in all_results.items():
        for combo_name, (result, latency) in results.items():
            all_latencies.append((combo_name, latency, format_name))
            # è®°å½• PyTorch ç¨ å¯†å®ç°çš„å»¶è¿Ÿä½œä¸ºåŸºå‡†
            if "PyTorch-1: ç¨ å¯† matmul" in combo_name:
                pytorch_dense_latency = latency
    
    # æŒ‰å»¶è¿Ÿæ’åº
    all_latencies.sort(key=lambda x: x[1])
    
    print("\nå»¶è¿Ÿæ’åï¼ˆä»å¿«åˆ°æ…¢ï¼‰ï¼š")
    print("-" * 86)
    if pytorch_dense_latency is not None:
        print(f"{'æ’å':<4} {'ç®—å­ç»„åˆ':<62} {'å»¶è¿Ÿ(ms)':<12} {'åŠ é€Ÿæ¯”':<10}")
        print("-" * 86)
        for rank, (combo_name, latency, format_name) in enumerate(all_latencies, 1):
            speedup = pytorch_dense_latency / latency if latency > 0 else 0.0
            # é«˜äº®æ˜¾ç¤ºè‡ªå®šä¹‰ç®—å­ï¼ˆéPyTorchï¼‰
            marker = "ğŸš€" if format_name != "PyTorch" else "ğŸ“Š"
            print(f"{rank:2d}. {marker} {combo_name:60s} {latency:8.4f} ms  {speedup:6.2f}x")
    else:
        for rank, (combo_name, latency, format_name) in enumerate(all_latencies, 1):
            print(f"{rank:2d}. {combo_name:60s} {latency:8.4f} ms")
    
    # æ‰¾å‡ºæœ€å¿«çš„ç»„åˆ
    fastest_name, fastest_latency, fastest_format = all_latencies[0]
    print("\n" + "=" * 80)
    print(f"âš¡ æœ€å¿«çš„ç»„åˆ: {fastest_name}")
    print(f"   å»¶è¿Ÿ: {fastest_latency:.4f} ms")
    if pytorch_dense_latency is not None:
        speedup = pytorch_dense_latency / fastest_latency
        print(f"   ç›¸æ¯”PyTorchç¨ å¯†å®ç°åŠ é€Ÿæ¯”: {speedup:.2f}x")
    print("=" * 80)
    
    # ç»Ÿè®¡è‡ªå®šä¹‰ç®—å­ vs PyTorch
    if pytorch_dense_latency is not None:
        print("\n" + "=" * 80)
        print("è‡ªå®šä¹‰ç®—å­æ€§èƒ½ç»Ÿè®¡")
        print("=" * 80)
        
        custom_latencies = [(name, lat) for name, lat, fmt in all_latencies if fmt != "PyTorch"]
        if custom_latencies:
            fastest_custom_name, fastest_custom_latency = custom_latencies[0]
            print(f"\næœ€å¿«çš„è‡ªå®šä¹‰ç®—å­: {fastest_custom_name}")
            print(f"  å»¶è¿Ÿ: {fastest_custom_latency:.4f} ms")
            print(f"  ç›¸æ¯”PyTorchç¨ å¯†å®ç°åŠ é€Ÿæ¯”: {pytorch_dense_latency/fastest_custom_latency:.2f}x")
            
            # ç»Ÿè®¡æœ‰å¤šå°‘è‡ªå®šä¹‰ç®—å­æ¯”PyTorchç¨ å¯†å®ç°å¿«
            faster_than_dense = sum(1 for _, lat in custom_latencies if lat < pytorch_dense_latency)
            print(f"\næ¯”PyTorchç¨ å¯†å®ç°æ›´å¿«çš„è‡ªå®šä¹‰ç®—å­æ•°é‡: {faster_than_dense}/{len(custom_latencies)}")
            
            # æ‰¾å‡ºPyTorchéç¨ å¯†å®ç°çš„å»¶è¿Ÿï¼ˆæ’é™¤ç¨ å¯†matmulï¼‰
            pytorch_nondense_latencies = [(name, lat) for name, lat, fmt in all_latencies 
                                          if fmt == "PyTorch" and "ç¨ å¯† matmul" not in name]
            if pytorch_nondense_latencies:
                fastest_pytorch_nondense = min(pytorch_nondense_latencies, key=lambda x: x[1])
                print(f"\nPyTorchæœ€å¿«çš„éç¨ å¯†å®ç°: {fastest_pytorch_nondense[0]}")
                print(f"  å»¶è¿Ÿ: {fastest_pytorch_nondense[1]:.4f} ms")
                faster_than_nondense = sum(1 for _, lat in custom_latencies if lat < fastest_pytorch_nondense[1])
                print(f"\næ¯”PyTorchæœ€å¿«éç¨ å¯†å®ç°æ›´å¿«çš„è‡ªå®šä¹‰ç®—å­æ•°é‡: {faster_than_nondense}/{len(custom_latencies)}")
        
        print("=" * 80)


def main() -> None:
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    parser = argparse.ArgumentParser()
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument("--threshold", type=float, default=0.9, help="ç¨€ç–åŒ–é˜ˆå€¼")
    parser.add_argument("--M", type=int, default=1, help="activation è¡Œæ•°")
    parser.add_argument("--K", type=int, default=64, help="activation åˆ—æ•° / weight è¡Œæ•°")
    parser.add_argument("--N", type=int, default=64, help="weight åˆ—æ•°")
    parser.add_argument(
        "--tests",
        nargs="+",
        default=["all"],
        help=(
            "é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•é¡¹ï¼ˆç©ºæ ¼æˆ–é€—å·åˆ†éš”ï¼‰ï¼š"
            "all/icsr/csr/coo/csc/pytorch/gemm-only/preprocess-only"
        ),
    )
    args = parser.parse_args()

    selected_tests = _parse_selected_tests(args.tests)
    
    print("=" * 80)
    print("ARM SVE ç¨€ç– GEMM ç®—å­ç»¼åˆæµ‹è¯•")
    print("=" * 80)
    print(f"é…ç½®å‚æ•°:")
    print(f"  - éšæœºç§å­: {args.seed}")
    print(f"  - é˜ˆå€¼: {args.threshold}")
    print(f"  - çŸ©é˜µå°ºå¯¸: activation ({args.M}, {args.K}), weight ({args.K}, {args.N})")
    print(f"  - æµ‹è¯•é¡¹: {', '.join(selected_tests)}")
    
    try:
        if psutil is None:
            print("  - CPU åˆ©ç”¨ç‡: psutil ä¸å¯ç”¨ï¼Œè·³è¿‡ CPU åˆ©ç”¨ç‡æ‰“å°ï¼ˆå¯é€‰å®‰è£…: pip install psutilï¼‰")
        else:
            _maybe_print_cpu_util("å¯åŠ¨å‰")

        # åŠ è½½æ‰©å±•
        load_sve_sparse_gemm_extension(verbose=False)
        
        # ç”Ÿæˆå…±äº«çš„æµ‹è¯•æ•°æ®
        activation = _make_random_sparse_activation(args.M, args.K, seed=args.seed)
        activation_thresholded = _apply_threshold(activation, threshold=args.threshold)

        # è®¡ç®—ç¨€ç–åº¦
        nnz = torch.count_nonzero(activation_thresholded).item()
        sparsity = 100.0 * (1.0 - nnz / (args.M * args.K))
        print(f"  - ç¨€ç–åº¦: {sparsity:.1f}% ({nnz}/{args.M * args.K} éé›¶å…ƒç´ )")

        needs_weight = any(
            t in {"icsr", "csr", "coo", "csc", "pytorch", "gemm-only"} for t in selected_tests
        )
        needs_reference = any(
            t in {"icsr", "csr", "coo", "csc", "pytorch", "gemm-only"} for t in selected_tests
        )

        weight = None
        reference = None
        if needs_weight:
            weight = torch.randn(args.K, args.N, dtype=torch.float32)
        if needs_reference:
            if weight is None:
                raise RuntimeError("å†…éƒ¨é”™è¯¯ï¼šneeds_reference=True ä½† weight æœªç”Ÿæˆ")
            reference = torch.matmul(activation_thresholded, weight)
        
        # ç»„åˆ/å‚è€ƒå®ç°æµ‹è¯•ï¼ˆä¼šå‚ä¸ correctness + summaryï¼‰
        all_results: Dict[str, Dict[str, Tuple[torch.Tensor, float]]] = {}
        if any(t in {"icsr", "csr", "coo", "csc", "pytorch"} for t in selected_tests):
            if weight is None or reference is None:
                raise RuntimeError("å†…éƒ¨é”™è¯¯ï¼šéœ€è¦ weight/reference ä½†æœªç”Ÿæˆ")

            if "icsr" in selected_tests:
                _maybe_print_cpu_util("å¼€å§‹ iCSR")
                all_results["iCSR"] = test_icsr_combinations(activation, weight, args.threshold)
                _maybe_print_cpu_util("ç»“æŸ iCSR")
            if "csr" in selected_tests:
                _maybe_print_cpu_util("å¼€å§‹ CSR")
                all_results["CSR"] = test_csr_combinations(activation, weight, args.threshold)
                _maybe_print_cpu_util("ç»“æŸ CSR")
            if "coo" in selected_tests:
                _maybe_print_cpu_util("å¼€å§‹ COO")
                all_results["COO"] = test_coo_combinations(activation, weight, args.threshold)
                _maybe_print_cpu_util("ç»“æŸ COO")
            if "csc" in selected_tests:
                _maybe_print_cpu_util("å¼€å§‹ CSC")
                all_results["CSC"] = test_csc_combinations(activation, weight, args.threshold)
                _maybe_print_cpu_util("ç»“æŸ CSC")
            if "pytorch" in selected_tests:
                _maybe_print_cpu_util("å¼€å§‹ PyTorch å‚è€ƒ")
                all_results["PyTorch"] = test_pytorch_references(activation, weight, args.threshold)
                _maybe_print_cpu_util("ç»“æŸ PyTorch å‚è€ƒ")

            # éªŒè¯æ­£ç¡®æ€§ + æ€§èƒ½æ€»ç»“
            verify_correctness(all_results, reference)
            print_performance_summary(all_results)

        # é¢å¤–æµ‹è¯• 1ï¼šåªæµ‹è¯•æ ¸å¿ƒä¹˜æ³•ï¼ˆGEMM-onlyï¼‰
        if "gemm-only" in selected_tests:
            if weight is None or reference is None:
                raise RuntimeError("GEMM-only æµ‹è¯•éœ€è¦ weight/referenceï¼Œä½†å½“å‰æœªç”Ÿæˆï¼ˆè¯·æ£€æŸ¥ --testsï¼‰")

            _maybe_print_cpu_util("å¼€å§‹ GEMM-only")
            gemm_only_results = test_core_gemm_only(
                activation=activation,
                activation_thresholded=activation_thresholded,
                weight=weight,
                threshold=args.threshold,
            )
            _maybe_print_cpu_util("ç»“æŸ GEMM-only")
            verify_correctness_flat(gemm_only_results, reference)
            baseline_gemm_latency = gemm_only_results[
                "GEMM-only: PyTorch torch.matmul(thresholded, weight)"
            ][1]
            _print_ranked_latencies(
                title="æ ¸å¿ƒä¹˜æ³•ï¼ˆGEMM-onlyï¼‰å»¶è¿Ÿæ’åï¼ˆbaseline=PyTorch torch.matmulï¼‰",
                latencies=[(k, v[1]) for k, v in gemm_only_results.items()],
                baseline_latency=baseline_gemm_latency,
            )

        # é¢å¤–æµ‹è¯• 2ï¼šåªæµ‹è¯•è¾“å…¥ç¨€ç–çŸ©é˜µå¤„ç†ï¼ˆPreprocess-onlyï¼‰
        if "preprocess-only" in selected_tests:
            _maybe_print_cpu_util("å¼€å§‹ Preprocess-only")
            preprocess_only_results = test_preprocess_only(
                activation=activation,
                threshold=args.threshold,
            )
            _maybe_print_cpu_util("ç»“æŸ Preprocess-only")
            # ä»¥ PyTorch threshold-only ä½œä¸º baselineï¼ˆæœ€å°åŒ–çš„é¢„å¤„ç†åŸºå‡†ï¼‰
            baseline_pre_latency = preprocess_only_results[
                "Preprocess-only: PyTorch _apply_threshold(abs>=thr)"
            ][1]
            _print_ranked_latencies(
                title="è¾“å…¥ç¨€ç–çŸ©é˜µå¤„ç†ï¼ˆPreprocess-onlyï¼‰å»¶è¿Ÿæ’åï¼ˆbaseline=PyTorch _apply_thresholdï¼‰",
                latencies=[(k, v[1]) for k, v in preprocess_only_results.items()],
                baseline_latency=baseline_pre_latency,
            )
        
        print("\n" + "=" * 80)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        print("=" * 80)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
