"""
ARM SVE ç¨€ç– GEMM ç®—å­çš„ç»¼åˆæµ‹è¯•è„šæœ¬ã€‚

æœ¬è„šæœ¬æµ‹è¯•ä¸åŒç¨€ç–æ ¼å¼çš„ç¨€ç–åŒ–ç®—å­å’ŒGEMMç®—å­çš„ç»„åˆï¼ˆå…±17ä¸ªï¼‰ï¼š

è‡ªå®šä¹‰ SVE ç®—å­ï¼ˆ13ä¸ªï¼‰ï¼š
- iCSR æ ¼å¼ç»„åˆï¼šthr_sparsify_to_icsr(_sve) + sparse_gemm_icsr(_sve_gather)
- CSR æ ¼å¼ç»„åˆï¼šthr_sparsify_to_csr(_sve) + sparse_gemm_csr(_sve_gather)
- COO æ ¼å¼ç»„åˆï¼šthr_sparsify_to_coo(_sve) + sparse_gemm_coo(_sve_gather)
- CSC æ ¼å¼ç»„åˆï¼šthr_sparsify_to_csc + sparse_gemm_csc

PyTorch å‚è€ƒå®ç°ï¼ˆ4ä¸ªï¼‰ï¼š
- ç¨ å¯† matmul
- ç¨€ç– CSR + sparse.mm
- ç¨€ç– CSC + sparse.mm
- é€‰æ‹©æ€§åŠ è½½ weight éé›¶è¡Œ + matmul

æµ‹è¯•å†…å®¹ï¼š
1. æ­£ç¡®æ€§éªŒè¯ï¼šä¸PyTorchå‚è€ƒå®ç°æ¯”è¾ƒ
2. æ€§èƒ½æµ‹è¯•ï¼šæµ‹é‡æ¯ä¸ªç»„åˆçš„å»¶è¿Ÿ
3. åŠ é€Ÿæ¯”è®¡ç®—ï¼šè®¡ç®—ç›¸å¯¹äºPyTorchç¨ å¯†å®ç°çš„åŠ é€Ÿæ¯”
4. æ€§èƒ½æ’åï¼šæ‰¾å‡ºæœ€å¿«çš„ç®—å­ç»„åˆ

è¿è¡Œæ–¹å¼:
    python -m scripts.test_sparse_formats
    python -m scripts.test_sparse_formats --threshold 0.8 --M 16 --K 512 --N 1024
"""

from __future__ import annotations

import argparse
import torch
from typing import Callable, Dict, List, Tuple

from kernels.cpp_sve_sparse_gemm import (
    # iCSR ç®—å­
    SparseGEMMiCSRSVEGatherKernel,
    SparseGEMMICSRKernel,
    thr_sparsify_to_icsr,
    thr_sparsify_to_icsr_sve,
    # CSR ç®—å­
    SparseGEMMCSRKernel,
    SparseGEMMCSRSVEGatherKernel,
    thr_sparsify_to_csr,
    thr_sparsify_to_csr_sve,
    # COO ç®—å­
    SparseGEMMCOOKernel,
    SparseGEMMCOOSVEGatherKernel,
    thr_sparsify_to_coo,
    thr_sparsify_to_coo_sve,
    # CSC ç®—å­
    SparseGEMMCSCKernel,
    thr_sparsify_to_csc,
    # å·¥å…·å‡½æ•°
    load_sve_sparse_gemm_extension,
)
from kernels.kernel_utils import measure_latency


def _make_random_sparse_activation(
    M: int,
    K: int,
    seed: int,
) -> torch.Tensor:
    """ç”Ÿæˆéšæœº activation çŸ©é˜µï¼ˆfloat32ï¼‰ã€‚"""
    g = torch.Generator()
    g.manual_seed(seed)
    x = torch.rand(M, K, dtype=torch.float32, generator=g)
    return x


def _apply_threshold(activation: torch.Tensor, threshold: float = 0.0) -> torch.Tensor:
    """å¯¹ activation çŸ©é˜µåº”ç”¨é˜ˆå€¼ï¼šabs(x) >= threshold çš„å€¼ä¿ç•™ï¼Œå…¶ä½™ç½®é›¶ã€‚

    æ³¨æ„ï¼šcpp_sve_sparse_gemm ä¸‹çš„ thr_sparsify_to_* ç³»åˆ—ç®—å­ä½¿ç”¨çš„æ˜¯ abs(x) >= thr çš„åˆ¤å®šï¼›
    è¿™é‡Œå¿…é¡»ä¿æŒä¸€è‡´ï¼Œå¦åˆ™ä¼šå‡ºç°ç³»ç»Ÿæ€§æ­£ç¡®æ€§åå·®ï¼ˆå°¤å…¶æ˜¯ activation å«è´Ÿå€¼æ—¶ï¼‰ã€‚
    """
    return torch.where(activation.abs() >= threshold, activation, torch.zeros_like(activation))


# =============================================================================
# iCSR æ ¼å¼ç»„åˆæµ‹è¯•
# =============================================================================

def test_icsr_combinations(
    activation: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """
    æµ‹è¯• iCSR æ ¼å¼çš„ç¨€ç–åŒ–å’ŒGEMMç®—å­çš„æ‰€æœ‰ç»„åˆã€‚
    
    ç»„åˆï¼š
    - thr_sparsify_to_icsr + sparse_gemm_icsr_sve_gather
    - thr_sparsify_to_icsr_sve + sparse_gemm_icsr_sve_gather
    - thr_sparsify_to_icsr + sparse_gemm_icsr
    - thr_sparsify_to_icsr_sve + sparse_gemm_icsr
    
    Returns:
        Dict[ç»„åˆåç§°, (ç»“æœ, å»¶è¿Ÿ)]
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯• iCSR æ ¼å¼ç»„åˆ")
    print("=" * 80)
    
    results = {}
    
    # åˆå§‹åŒ– GEMM ç®—å­
    icsr_sve_gather_kernel = SparseGEMMiCSRSVEGatherKernel.initialize(
        name="sparse_gemm_icsr_sve_gather", target="CPU"
    )
    icsr_sve_gather_op = icsr_sve_gather_kernel.operator(compiled=True)
    
    icsr_kernel = SparseGEMMICSRKernel.initialize(
        name="sparse_gemm_icsr", target="CPU"
    )
    icsr_op = icsr_kernel.operator(compiled=True)
    
    # ç»„åˆ 1: thr_sparsify_to_icsr + sparse_gemm_icsr_sve_gather
    print("\n[iCSR-1] thr_sparsify_to_icsr + sparse_gemm_icsr_sve_gather")
    def icsr_combo1():
        nz_counts, nz_col_indices, row_offsets = thr_sparsify_to_icsr(activation, threshold)
        return icsr_sve_gather_op(activation, weight, row_offsets, nz_col_indices)
    
    lat1 = measure_latency(icsr_combo1, warmup=5, iters=100)
    result1 = icsr_combo1()
    results["iCSR-1: thr_sparsify_to_icsr + sparse_gemm_icsr_sve_gather"] = (result1, lat1)
    print(f"  å»¶è¿Ÿ: {lat1:.4f} ms")
    
    # ç»„åˆ 2: thr_sparsify_to_icsr_sve + sparse_gemm_icsr_sve_gather
    print("\n[iCSR-2] thr_sparsify_to_icsr_sve + sparse_gemm_icsr_sve_gather")
    def icsr_combo2():
        nz_counts, nz_col_indices, row_offsets = thr_sparsify_to_icsr_sve(activation, threshold)
        return icsr_sve_gather_op(activation, weight, row_offsets, nz_col_indices)
    
    lat2 = measure_latency(icsr_combo2, warmup=5, iters=100)
    result2 = icsr_combo2()
    results["iCSR-2: thr_sparsify_to_icsr_sve + sparse_gemm_icsr_sve_gather"] = (result2, lat2)
    print(f"  å»¶è¿Ÿ: {lat2:.4f} ms")
    
    # ç»„åˆ 3: thr_sparsify_to_icsr + sparse_gemm_icsr
    print("\n[iCSR-3] thr_sparsify_to_icsr + sparse_gemm_icsr")
    def icsr_combo3():
        nz_counts, nz_col_indices, row_offsets = thr_sparsify_to_icsr(activation, threshold)
        return icsr_op(activation, weight, row_offsets, nz_col_indices)
    
    lat3 = measure_latency(icsr_combo3, warmup=5, iters=100)
    result3 = icsr_combo3()
    results["iCSR-3: thr_sparsify_to_icsr + sparse_gemm_icsr"] = (result3, lat3)
    print(f"  å»¶è¿Ÿ: {lat3:.4f} ms")
    
    # ç»„åˆ 4: thr_sparsify_to_icsr_sve + sparse_gemm_icsr
    print("\n[iCSR-4] thr_sparsify_to_icsr_sve + sparse_gemm_icsr")
    def icsr_combo4():
        nz_counts, nz_col_indices, row_offsets = thr_sparsify_to_icsr_sve(activation, threshold)
        return icsr_op(activation, weight, row_offsets, nz_col_indices)
    
    lat4 = measure_latency(icsr_combo4, warmup=5, iters=100)
    result4 = icsr_combo4()
    results["iCSR-4: thr_sparsify_to_icsr_sve + sparse_gemm_icsr"] = (result4, lat4)
    print(f"  å»¶è¿Ÿ: {lat4:.4f} ms")
    
    return results


# =============================================================================
# CSR æ ¼å¼ç»„åˆæµ‹è¯•
# =============================================================================

def test_csr_combinations(
    activation: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """
    æµ‹è¯• CSR æ ¼å¼çš„ç¨€ç–åŒ–å’ŒGEMMç®—å­çš„æ‰€æœ‰ç»„åˆã€‚
    
    ç»„åˆï¼š
    - thr_sparsify_to_csr + sparse_gemm_csr
    - thr_sparsify_to_csr_sve + sparse_gemm_csr
    - thr_sparsify_to_csr + sparse_gemm_csr_sve_gather
    - thr_sparsify_to_csr_sve + sparse_gemm_csr_sve_gather
    
    Returns:
        Dict[ç»„åˆåç§°, (ç»“æœ, å»¶è¿Ÿ)]
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯• CSR æ ¼å¼ç»„åˆ")
    print("=" * 80)
    
    results = {}
    
    # åˆå§‹åŒ– GEMM ç®—å­
    csr_kernel = SparseGEMMCSRKernel.initialize(
        name="sparse_gemm_csr", target="CPU"
    )
    csr_op = csr_kernel.operator(compiled=True)
    
    csr_sve_gather_kernel = SparseGEMMCSRSVEGatherKernel.initialize(
        name="sparse_gemm_csr_sve_gather", target="CPU"
    )
    csr_sve_gather_op = csr_sve_gather_kernel.operator(compiled=True)
    
    # ç»„åˆ 1: thr_sparsify_to_csr + sparse_gemm_csr
    print("\n[CSR-1] thr_sparsify_to_csr + sparse_gemm_csr")
    def csr_combo1():
        row_offsets, nz_col_indices, values = thr_sparsify_to_csr(activation, threshold)
        return csr_op(weight, row_offsets, nz_col_indices, values)
    
    lat1 = measure_latency(csr_combo1, warmup=5, iters=100)
    result1 = csr_combo1()
    results["CSR-1: thr_sparsify_to_csr + sparse_gemm_csr"] = (result1, lat1)
    print(f"  å»¶è¿Ÿ: {lat1:.4f} ms")
    
    # ç»„åˆ 2: thr_sparsify_to_csr_sve + sparse_gemm_csr
    print("\n[CSR-2] thr_sparsify_to_csr_sve + sparse_gemm_csr")
    def csr_combo2():
        row_offsets, nz_col_indices, values = thr_sparsify_to_csr_sve(activation, threshold)
        return csr_op(weight, row_offsets, nz_col_indices, values)
    
    lat2 = measure_latency(csr_combo2, warmup=5, iters=100)
    result2 = csr_combo2()
    results["CSR-2: thr_sparsify_to_csr_sve + sparse_gemm_csr"] = (result2, lat2)
    print(f"  å»¶è¿Ÿ: {lat2:.4f} ms")
    
    # ç»„åˆ 3: thr_sparsify_to_csr + sparse_gemm_csr_sve_gather
    print("\n[CSR-3] thr_sparsify_to_csr + sparse_gemm_csr_sve_gather")
    def csr_combo3():
        row_offsets, nz_col_indices, values = thr_sparsify_to_csr(activation, threshold)
        return csr_sve_gather_op(weight, row_offsets, nz_col_indices, values)
    
    lat3 = measure_latency(csr_combo3, warmup=5, iters=100)
    result3 = csr_combo3()
    results["CSR-3: thr_sparsify_to_csr + sparse_gemm_csr_sve_gather"] = (result3, lat3)
    print(f"  å»¶è¿Ÿ: {lat3:.4f} ms")
    
    # ç»„åˆ 4: thr_sparsify_to_csr_sve + sparse_gemm_csr_sve_gather
    print("\n[CSR-4] thr_sparsify_to_csr_sve + sparse_gemm_csr_sve_gather")
    def csr_combo4():
        row_offsets, nz_col_indices, values = thr_sparsify_to_csr_sve(activation, threshold)
        return csr_sve_gather_op(weight, row_offsets, nz_col_indices, values)
    
    lat4 = measure_latency(csr_combo4, warmup=5, iters=100)
    result4 = csr_combo4()
    results["CSR-4: thr_sparsify_to_csr_sve + sparse_gemm_csr_sve_gather"] = (result4, lat4)
    print(f"  å»¶è¿Ÿ: {lat4:.4f} ms")
    
    return results


# =============================================================================
# COO æ ¼å¼ç»„åˆæµ‹è¯•
# =============================================================================

def test_coo_combinations(
    activation: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """
    æµ‹è¯• COO æ ¼å¼çš„ç¨€ç–åŒ–å’ŒGEMMç®—å­çš„æ‰€æœ‰ç»„åˆã€‚
    
    ç»„åˆï¼š
    - thr_sparsify_to_coo + sparse_gemm_coo
    - thr_sparsify_to_coo_sve + sparse_gemm_coo
    - thr_sparsify_to_coo + sparse_gemm_coo_sve_gather
    - thr_sparsify_to_coo_sve + sparse_gemm_coo_sve_gather
    
    Returns:
        Dict[ç»„åˆåç§°, (ç»“æœ, å»¶è¿Ÿ)]
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯• COO æ ¼å¼ç»„åˆ")
    print("=" * 80)
    
    results = {}
    
    # åˆå§‹åŒ– GEMM ç®—å­
    coo_kernel = SparseGEMMCOOKernel.initialize(
        name="sparse_gemm_coo", target="CPU"
    )
    coo_op = coo_kernel.operator(compiled=True)
    
    coo_sve_gather_kernel = SparseGEMMCOOSVEGatherKernel.initialize(
        name="sparse_gemm_coo_sve_gather", target="CPU"
    )
    coo_sve_gather_op = coo_sve_gather_kernel.operator(compiled=True)
    
    # C++ ç®—å­ç­¾åéœ€è¦æ˜¾å¼ä¼ å…¥ Mï¼ˆç¨€ç–çŸ©é˜µè¡Œæ•°ï¼‰
    M = int(activation.size(0))

    # ç»„åˆ 1: thr_sparsify_to_coo + sparse_gemm_coo
    print("\n[COO-1] thr_sparsify_to_coo + sparse_gemm_coo")
    def coo_combo1():
        row_indices, col_indices, values = thr_sparsify_to_coo(activation, threshold)
        # sparse_gemm_coo éœ€è¦ int64 çš„ col_indicesï¼Œthr_sparsify_to_coo è¿”å› uint32
        col_indices_i64 = col_indices.to(torch.int64)
        return coo_op(weight, row_indices, col_indices_i64, values, M)
    
    lat1 = measure_latency(coo_combo1, warmup=5, iters=1000)
    result1 = coo_combo1()
    results["COO-1: thr_sparsify_to_coo + sparse_gemm_coo"] = (result1, lat1)
    print(f"  å»¶è¿Ÿ: {lat1:.4f} ms")
    
    # ç»„åˆ 2: thr_sparsify_to_coo_sve + sparse_gemm_coo
    print("\n[COO-2] thr_sparsify_to_coo_sve + sparse_gemm_coo")
    def coo_combo2():
        row_indices, col_indices, values = thr_sparsify_to_coo_sve(activation, threshold)
        # sparse_gemm_coo éœ€è¦ int64 çš„ col_indicesï¼Œthr_sparsify_to_coo_sve è¿”å› uint32
        col_indices_i64 = col_indices.to(torch.int64)
        return coo_op(weight, row_indices, col_indices_i64, values, M)
    
    lat2 = measure_latency(coo_combo2, warmup=5, iters=1000)
    result2 = coo_combo2()
    results["COO-2: thr_sparsify_to_coo_sve + sparse_gemm_coo"] = (result2, lat2)
    print(f"  å»¶è¿Ÿ: {lat2:.4f} ms")
    
    # ç»„åˆ 3: thr_sparsify_to_coo + sparse_gemm_coo_sve_gather
    print("\n[COO-3] thr_sparsify_to_coo + sparse_gemm_coo_sve_gather")
    def coo_combo3():
        row_indices, col_indices, values = thr_sparsify_to_coo(activation, threshold)
        # sparse_gemm_coo_sve_gather éœ€è¦ uint32 çš„ col_indicesï¼Œå·²ç»æ˜¯ uint32
        return coo_sve_gather_op(weight, row_indices, col_indices, values, M)
    
    lat3 = measure_latency(coo_combo3, warmup=5, iters=1000)
    result3 = coo_combo3()
    results["COO-3: thr_sparsify_to_coo + sparse_gemm_coo_sve_gather"] = (result3, lat3)
    print(f"  å»¶è¿Ÿ: {lat3:.4f} ms")
    
    # ç»„åˆ 4: thr_sparsify_to_coo_sve + sparse_gemm_coo_sve_gather
    print("\n[COO-4] thr_sparsify_to_coo_sve + sparse_gemm_coo_sve_gather")
    def coo_combo4():
        row_indices, col_indices, values = thr_sparsify_to_coo_sve(activation, threshold)
        # sparse_gemm_coo_sve_gather éœ€è¦ uint32 çš„ col_indicesï¼Œå·²ç»æ˜¯ uint32
        return coo_sve_gather_op(weight, row_indices, col_indices, values, M)
    
    lat4 = measure_latency(coo_combo4, warmup=5, iters=1000)
    result4 = coo_combo4()
    results["COO-4: thr_sparsify_to_coo_sve + sparse_gemm_coo_sve_gather"] = (result4, lat4)
    print(f"  å»¶è¿Ÿ: {lat4:.4f} ms")
    
    return results


# =============================================================================
# CSC æ ¼å¼ç»„åˆæµ‹è¯•
# =============================================================================

def test_csc_combinations(
    activation: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """
    æµ‹è¯• CSC æ ¼å¼çš„ç¨€ç–åŒ–å’ŒGEMMç®—å­çš„æ‰€æœ‰ç»„åˆã€‚
    
    ç»„åˆï¼š
    - thr_sparsify_to_csc + sparse_gemm_csc
    
    Returns:
        Dict[ç»„åˆåç§°, (ç»“æœ, å»¶è¿Ÿ)]
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯• CSC æ ¼å¼ç»„åˆ")
    print("=" * 80)
    
    results = {}
    
    # åˆå§‹åŒ– GEMM ç®—å­
    csc_kernel = SparseGEMMCSCKernel.initialize(
        name="sparse_gemm_csc", target="CPU"
    )
    csc_op = csc_kernel.operator(compiled=True)
    
    M = activation.size(0)
    
    # ç»„åˆ 1: thr_sparsify_to_csc + sparse_gemm_csc
    print("\n[CSC-1] thr_sparsify_to_csc + sparse_gemm_csc")
    def csc_combo1():
        col_ptr, row_indices, values = thr_sparsify_to_csc(activation, threshold)
        return csc_op(weight, col_ptr, row_indices, values, M, 0)
    
    lat1 = measure_latency(csc_combo1, warmup=5, iters=100)
    result1 = csc_combo1()
    results["CSC-1: thr_sparsify_to_csc + sparse_gemm_csc"] = (result1, lat1)
    print(f"  å»¶è¿Ÿ: {lat1:.4f} ms")
    
    return results


# =============================================================================
# PyTorch å‚è€ƒå®ç°æµ‹è¯•
# =============================================================================

def test_pytorch_references(
    activation: torch.Tensor,
    weight: torch.Tensor,
    threshold: float,
) -> Dict[str, Tuple[torch.Tensor, float]]:
    """
    æµ‹è¯•PyTorchçš„å‚è€ƒå®ç°ã€‚
    
    æµ‹è¯•æ–¹æ³•ï¼š
    - PyTorch ç¨ å¯† matmul
    - PyTorch ç¨€ç– CSR + sparse.mm
    - PyTorch ç¨€ç– CSC + sparse.mm
    - PyTorch é€‰æ‹©æ€§åŠ è½½ weight éé›¶è¡Œ + matmul
    
    Returns:
        Dict[ç»„åˆåç§°, (ç»“æœ, å»¶è¿Ÿ)]
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯• PyTorch å‚è€ƒå®ç°")
    print("=" * 80)
    
    results = {}
    
    # å¯ç”¨ MKL-DNN
    torch.backends.mkldnn.enabled = True
    
    # PyTorch ç¨ å¯† matmul
    print("\n[PyTorch-1] ç¨ å¯† matmul")
    def pytorch_dense_fn():
        activation_thresholded = _apply_threshold(activation, threshold=threshold)
        return torch.matmul(activation_thresholded, weight)
    
    lat1 = measure_latency(pytorch_dense_fn, warmup=5, iters=100)
    result1 = pytorch_dense_fn()
    results["PyTorch-1: ç¨ å¯† matmul"] = (result1, lat1)
    print(f"  å»¶è¿Ÿ: {lat1:.4f} ms")
    
    # PyTorch ç¨€ç– CSR + sparse.mm
    print("\n[PyTorch-2] ç¨€ç– CSR + sparse.mm")
    def pytorch_sparse_csr_fn():
        activation_thresholded = _apply_threshold(activation, threshold=threshold)
        sp_act = activation_thresholded.to_sparse_csr()
        return torch.sparse.mm(sp_act, weight)
    
    lat2 = measure_latency(pytorch_sparse_csr_fn, warmup=5, iters=100)
    result2 = pytorch_sparse_csr_fn()
    results["PyTorch-2: ç¨€ç– CSR + sparse.mm"] = (result2, lat2)
    print(f"  å»¶è¿Ÿ: {lat2:.4f} ms")
    
    # PyTorch ç¨€ç– CSC + sparse.mm
    print("\n[PyTorch-3] ç¨€ç– CSC + sparse.mm")
    def pytorch_sparse_csc_fn():
        activation_thresholded = _apply_threshold(activation, threshold=threshold)
        sp_act = activation_thresholded.to_sparse_csc()
        return torch.sparse.mm(sp_act, weight)
    
    lat3 = measure_latency(pytorch_sparse_csc_fn, warmup=5, iters=100)
    result3 = pytorch_sparse_csc_fn()
    results["PyTorch-3: ç¨€ç– CSC + sparse.mm"] = (result3, lat3)
    print(f"  å»¶è¿Ÿ: {lat3:.4f} ms")
    
    # PyTorch é€‰æ‹©æ€§åŠ è½½ weight éé›¶è¡Œ + matmul
    print("\n[PyTorch-4] é€‰æ‹©æ€§åŠ è½½ weight éé›¶è¡Œ + matmul")
    def pytorch_selective_weight_fn():
        activation_thresholded = _apply_threshold(activation, threshold=threshold)
        M, K = activation_thresholded.shape
        N = weight.shape[1]
        
        # åˆå§‹åŒ–è¾“å‡º
        output = torch.zeros(M, N, dtype=torch.float32)
        
        # å¯¹æ¯ä¸€è¡Œè¿›è¡Œå¤„ç†
        for m in range(M):
            # æ‰¾å‡ºè¯¥è¡Œçš„éé›¶åˆ—ç´¢å¼•
            nz_cols = torch.nonzero(activation_thresholded[m], as_tuple=False).flatten()
            
            if nz_cols.numel() > 0:
                # åªé€‰æ‹© weight ä¸­å¯¹åº”çš„éé›¶è¡Œ
                act_nz = activation_thresholded[m, nz_cols]  # (nnz,)
                weight_nz = weight[nz_cols, :]  # (nnz, N)
                
                # è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼š(1, nnz) @ (nnz, N) -> (1, N)
                output[m] = torch.matmul(act_nz.unsqueeze(0), weight_nz).squeeze(0)
        
        return output
    
    lat4 = measure_latency(pytorch_selective_weight_fn, warmup=5, iters=100)
    result4 = pytorch_selective_weight_fn()
    results["PyTorch-4: é€‰æ‹©æ€§åŠ è½½ weight éé›¶è¡Œ + matmul"] = (result4, lat4)
    print(f"  å»¶è¿Ÿ: {lat4:.4f} ms")
    
    return results


# =============================================================================
# æ­£ç¡®æ€§éªŒè¯å’Œç»¼åˆæ¯”è¾ƒ
# =============================================================================

def verify_correctness(
    all_results: Dict[str, Dict[str, Tuple[torch.Tensor, float]]],
    reference: torch.Tensor,
) -> None:
    """éªŒè¯æ‰€æœ‰ç®—å­ç»„åˆçš„æ­£ç¡®æ€§ã€‚"""
    print("\n" + "=" * 80)
    print("æ­£ç¡®æ€§éªŒè¯")
    print("=" * 80)
    
    all_passed = True
    
    for format_name, results in all_results.items():
        print(f"\n{format_name}:")
        for combo_name, (result, latency) in results.items():
            max_diff = torch.max(torch.abs(result - reference)).item()
            mean_diff = torch.mean(torch.abs(result - reference)).item()
            
            is_correct = torch.allclose(result, reference, rtol=1e-4, atol=1e-5)
            status = "âœ…" if is_correct else "âŒ"
            
            print(f"  {status} {combo_name}")
            print(f"      æœ€å¤§è¯¯å·®: {max_diff:.6e}, å¹³å‡è¯¯å·®: {mean_diff:.6e}")
            
            if not is_correct:
                all_passed = False
    
    if all_passed:
        print("\nâœ… æ‰€æœ‰ç»„åˆçš„æ­£ç¡®æ€§æµ‹è¯•é€šè¿‡")
    else:
        print("\nâŒ éƒ¨åˆ†ç»„åˆçš„æ­£ç¡®æ€§æµ‹è¯•å¤±è´¥")


def print_performance_summary(
    all_results: Dict[str, Dict[str, Tuple[torch.Tensor, float]]],
) -> None:
    """æ‰“å°æ€§èƒ½å¯¹æ¯”æ€»ç»“ã€‚"""
    print("\n" + "=" * 80)
    print("æ€§èƒ½å¯¹æ¯”æ€»ç»“")
    print("=" * 80)
    
    # æ”¶é›†æ‰€æœ‰å»¶è¿Ÿæ•°æ®
    all_latencies = []
    pytorch_dense_latency = None
    
    for format_name, results in all_results.items():
        for combo_name, (result, latency) in results.items():
            all_latencies.append((combo_name, latency, format_name))
            # è®°å½• PyTorch ç¨ å¯†å®ç°çš„å»¶è¿Ÿä½œä¸ºåŸºå‡†
            if "PyTorch-1: ç¨ å¯† matmul" in combo_name:
                pytorch_dense_latency = latency
    
    # æŒ‰å»¶è¿Ÿæ’åº
    all_latencies.sort(key=lambda x: x[1])
    
    print("\nå»¶è¿Ÿæ’åï¼ˆä»å¿«åˆ°æ…¢ï¼‰ï¼š")
    print("-" * 86)
    if pytorch_dense_latency is not None:
        print(f"{'æ’å':<4} {'ç®—å­ç»„åˆ':<62} {'å»¶è¿Ÿ(ms)':<12} {'åŠ é€Ÿæ¯”':<10}")
        print("-" * 86)
        for rank, (combo_name, latency, format_name) in enumerate(all_latencies, 1):
            speedup = pytorch_dense_latency / latency if latency > 0 else 0.0
            # é«˜äº®æ˜¾ç¤ºè‡ªå®šä¹‰ç®—å­ï¼ˆéPyTorchï¼‰
            marker = "ğŸš€" if format_name != "PyTorch" else "ğŸ“Š"
            print(f"{rank:2d}. {marker} {combo_name:60s} {latency:8.4f} ms  {speedup:6.2f}x")
    else:
        for rank, (combo_name, latency, format_name) in enumerate(all_latencies, 1):
            print(f"{rank:2d}. {combo_name:60s} {latency:8.4f} ms")
    
    # æ‰¾å‡ºæœ€å¿«çš„ç»„åˆ
    fastest_name, fastest_latency, fastest_format = all_latencies[0]
    print("\n" + "=" * 80)
    print(f"âš¡ æœ€å¿«çš„ç»„åˆ: {fastest_name}")
    print(f"   å»¶è¿Ÿ: {fastest_latency:.4f} ms")
    if pytorch_dense_latency is not None:
        speedup = pytorch_dense_latency / fastest_latency
        print(f"   ç›¸æ¯”PyTorchç¨ å¯†å®ç°åŠ é€Ÿæ¯”: {speedup:.2f}x")
    print("=" * 80)
    
    # ç»Ÿè®¡è‡ªå®šä¹‰ç®—å­ vs PyTorch
    if pytorch_dense_latency is not None:
        print("\n" + "=" * 80)
        print("è‡ªå®šä¹‰ç®—å­æ€§èƒ½ç»Ÿè®¡")
        print("=" * 80)
        
        custom_latencies = [(name, lat) for name, lat, fmt in all_latencies if fmt != "PyTorch"]
        if custom_latencies:
            fastest_custom_name, fastest_custom_latency = custom_latencies[0]
            print(f"\næœ€å¿«çš„è‡ªå®šä¹‰ç®—å­: {fastest_custom_name}")
            print(f"  å»¶è¿Ÿ: {fastest_custom_latency:.4f} ms")
            print(f"  ç›¸æ¯”PyTorchç¨ å¯†å®ç°åŠ é€Ÿæ¯”: {pytorch_dense_latency/fastest_custom_latency:.2f}x")
            
            # ç»Ÿè®¡æœ‰å¤šå°‘è‡ªå®šä¹‰ç®—å­æ¯”PyTorchç¨ å¯†å®ç°å¿«
            faster_than_dense = sum(1 for _, lat in custom_latencies if lat < pytorch_dense_latency)
            print(f"\næ¯”PyTorchç¨ å¯†å®ç°æ›´å¿«çš„è‡ªå®šä¹‰ç®—å­æ•°é‡: {faster_than_dense}/{len(custom_latencies)}")
            
            # æ‰¾å‡ºPyTorchéç¨ å¯†å®ç°çš„å»¶è¿Ÿï¼ˆæ’é™¤ç¨ å¯†matmulï¼‰
            pytorch_nondense_latencies = [(name, lat) for name, lat, fmt in all_latencies 
                                          if fmt == "PyTorch" and "ç¨ å¯† matmul" not in name]
            if pytorch_nondense_latencies:
                fastest_pytorch_nondense = min(pytorch_nondense_latencies, key=lambda x: x[1])
                print(f"\nPyTorchæœ€å¿«çš„éç¨ å¯†å®ç°: {fastest_pytorch_nondense[0]}")
                print(f"  å»¶è¿Ÿ: {fastest_pytorch_nondense[1]:.4f} ms")
                faster_than_nondense = sum(1 for _, lat in custom_latencies if lat < fastest_pytorch_nondense[1])
                print(f"\næ¯”PyTorchæœ€å¿«éç¨ å¯†å®ç°æ›´å¿«çš„è‡ªå®šä¹‰ç®—å­æ•°é‡: {faster_than_nondense}/{len(custom_latencies)}")
        
        print("=" * 80)


def main() -> None:
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    parser = argparse.ArgumentParser()
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument("--threshold", type=float, default=0.8, help="ç¨€ç–åŒ–é˜ˆå€¼")
    parser.add_argument("--M", type=int, default=1, help="activation è¡Œæ•°")
    parser.add_argument("--K", type=int, default=4096, help="activation åˆ—æ•° / weight è¡Œæ•°")
    parser.add_argument("--N", type=int, default=11008, help="weight åˆ—æ•°")
    args = parser.parse_args()
    
    print("=" * 80)
    print("ARM SVE ç¨€ç– GEMM ç®—å­ç»¼åˆæµ‹è¯•")
    print("=" * 80)
    print(f"é…ç½®å‚æ•°:")
    print(f"  - éšæœºç§å­: {args.seed}")
    print(f"  - é˜ˆå€¼: {args.threshold}")
    print(f"  - çŸ©é˜µå°ºå¯¸: activation ({args.M}, {args.K}), weight ({args.K}, {args.N})")
    
    try:
        # åŠ è½½æ‰©å±•
        load_sve_sparse_gemm_extension(verbose=False)
        
        # ç”Ÿæˆå…±äº«çš„æµ‹è¯•æ•°æ®
        activation = _make_random_sparse_activation(args.M, args.K, seed=args.seed)
        weight = torch.randn(args.K, args.N, dtype=torch.float32)
        
        # è®¡ç®—å‚è€ƒç»“æœ
        activation_thresholded = _apply_threshold(activation, threshold=args.threshold)
        reference = torch.matmul(activation_thresholded, weight)
        
        # è®¡ç®—ç¨€ç–åº¦
        nnz = torch.count_nonzero(activation_thresholded).item()
        sparsity = 100.0 * (1.0 - nnz / (args.M * args.K))
        print(f"  - ç¨€ç–åº¦: {sparsity:.1f}% ({nnz}/{args.M * args.K} éé›¶å…ƒç´ )")
        
        # æµ‹è¯•æ‰€æœ‰æ ¼å¼ç»„åˆ
        all_results = {}
        
        all_results["iCSR"] = test_icsr_combinations(activation, weight, args.threshold)
        all_results["CSR"] = test_csr_combinations(activation, weight, args.threshold)
        all_results["COO"] = test_coo_combinations(activation, weight, args.threshold)
        all_results["CSC"] = test_csc_combinations(activation, weight, args.threshold)
        
        # æµ‹è¯• PyTorch å‚è€ƒå®ç°
        all_results["PyTorch"] = test_pytorch_references(activation, weight, args.threshold)
        
        # éªŒè¯æ­£ç¡®æ€§
        verify_correctness(all_results, reference)
        
        # æ‰“å°æ€§èƒ½æ€»ç»“
        print_performance_summary(all_results)
        
        print("\n" + "=" * 80)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        print("=" * 80)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
